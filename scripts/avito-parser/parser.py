#!/usr/bin/env python3
"""
–ü–∞—Ä—Å–µ—Ä —Ü–µ–Ω MacBook —Å –ê–≤–∏—Ç–æ –¥–ª—è BestMac.ru

–ò—Å–ø–æ–ª—å–∑—É–µ—Ç —Ç–∞–±–ª–∏—Ü—É URL –∏–∑ avito-urls.json –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–π.
–ö–∞–∂–¥–∞—è —Å—Ç—Ä–æ–∫–∞ = –º–æ–¥–µ–ª—å + RAM + SSD + –≥–æ—Ç–æ–≤–∞—è —Å—Å—ã–ª–∫–∞ –Ω–∞ –ø–æ–∏—Å–∫ Avito —Å —Ñ–∏–ª—å—Ç—Ä–∞–º–∏.

–§–æ—Ä–º–∞—Ç –º–æ–¥–µ–ª–∏: "MacBook Pro 14 (2021, M1 Pro)"

–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:
  python parser.py [pages]  # pages = –∫–æ–ª-–≤–æ —Å—Ç—Ä–∞–Ω–∏—Ü (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 2)

–¢—Ä–µ–±–æ–≤–∞–Ω–∏—è:
  pip install requests beautifulsoup4 lxml
"""

import json
import os
import re
import time
import random
import statistics
from datetime import datetime
from pathlib import Path
from dataclasses import dataclass, asdict
from typing import Optional

try:
    import requests
    from bs4 import BeautifulSoup
except ImportError:
    print("–£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏: pip install requests beautifulsoup4 lxml")
    exit(1)


# –ü—É—Ç–∏ –∫ —Ñ–∞–π–ª–∞–º
SCRIPT_DIR = Path(__file__).parent
URLS_FILE = SCRIPT_DIR / "../../public/data/avito-urls.json"
OUTPUT_FILE = SCRIPT_DIR / "../../public/data/avito-prices.json"
BUYOUT_FILE = SCRIPT_DIR / "../../public/data/buyout.json"

# –ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–±—ä—è–≤–ª–µ–Ω–∏–π –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
MIN_SAMPLES_FOR_ANALYSIS = 10

# –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –ø–∞—Ä—Å–µ—Ä–∞ –¥–ª—è –æ–±—Ö–æ–¥–∞ rate limiting
# –ó–∞–¥–µ—Ä–∂–∫–∞ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏ —Å—Ç—Ä–∞–Ω–∏—Ü (—Å–µ–∫—É–Ω–¥—ã)
PAGE_DELAY_MIN = 8.0
PAGE_DELAY_MAX = 15.0

# –ó–∞–¥–µ—Ä–∂–∫–∞ –º–µ–∂–¥—É –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è–º–∏ (—Å–µ–∫—É–Ω–¥—ã) - –≤–∞–∂–Ω–æ –¥–ª—è –∏–∑–±–µ–∂–∞–Ω–∏—è 429!
CONFIG_DELAY_MIN = 30.0
CONFIG_DELAY_MAX = 60.0

# –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–∞–Ω–∏—Ü –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é (2 –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–ª—è ~100 –æ–±—ä—è–≤–ª–µ–Ω–∏–π)
DEFAULT_PAGES = 2


@dataclass
class PriceStat:
    """–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Ü–µ–Ω –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏"""
    model_name: str      # "MacBook Pro 14 (2021, M1 Pro)"
    processor: str       # "Apple M1", "Apple M1 Pro"
    ram: int             # GB
    ssd: int             # GB
    median_price: int
    min_price: int
    max_price: int
    buyout_price: int
    samples_count: int
    updated_at: str


# User-Agent –¥–ª—è –∑–∞–ø—Ä–æ—Å–æ–≤ (—Ä–∞–∑–Ω—ã–µ –±—Ä–∞—É–∑–µ—Ä—ã)
USER_AGENTS = [
    "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
    "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
    "Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:121.0) Gecko/20100101 Firefox/121.0",
    "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
    "Mozilla/5.0 (Macintosh; Intel Mac OS X 14_2) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.2 Safari/605.1.15",
]


AVITO_HOME_URL = "https://www.avito.ru/"

# –ü—Ä–æ–∫—Å–∏ (–±–µ—Ä—ë–º –∏–∑ —Å–µ–∫—Ä–µ—Ç–æ–≤, –µ—Å–ª–∏ –µ—Å—Ç—å)
PROXY_URL = os.environ.get("PROXY_URL", "").strip()
CHANGE_IP_URL = os.environ.get("CHANGE_IP_URL", "").strip()

def rotate_ip():
    """–°–º–µ–Ω–∞ IP –¥–ª—è –º–æ–±–∏–ª—å–Ω—ã—Ö –ø—Ä–æ–∫—Å–∏"""
    if CHANGE_IP_URL:
        try:
            print(f"üîÑ –°–º–µ–Ω–∞ IP —á–µ—Ä–µ–∑ {CHANGE_IP_URL}...")
            resp = requests.get(CHANGE_IP_URL, timeout=15)
            print(f"üì° –û—Ç–≤–µ—Ç —Å–µ—Ä–≤–∏—Å–∞: {resp.text.strip()}")
            # –î–∞–µ–º –≤—Ä–µ–º—è –Ω–∞ –ø–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–µ
            time.sleep(5)
            return True
        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–º–µ–Ω–µ IP: {e}")
    return False

# –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–æ–∫—Å–∏ –¥–ª—è requests
if PROXY_URL:
    # –£–¥–∞–ª—è–µ–º –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã –∏ –∫–∞–≤—ã—á–∫–∏, –µ—Å–ª–∏ –æ–Ω–∏ –µ—Å—Ç—å
    PROXY_URL = PROXY_URL.strip().strip('"').strip("'")
    
    # –ï—Å–ª–∏ –ø—Ä–æ–∫—Å–∏ —É–∂–µ —Å–æ–¥–µ—Ä–∂–∏—Ç –ø—Ä–æ—Ç–æ–∫–æ–ª, –∏—Å–ø–æ–ª—å–∑—É–µ–º –∫–∞–∫ –µ—Å—Ç—å
    if PROXY_URL.startswith(("http://", "https://", "socks5://")):
        pass
    # –ü–æ–¥–¥–µ—Ä–∂–∫–∞ —Ñ–æ—Ä–º–∞—Ç–∞ IP:PORT:USER:PASS
    elif len(PROXY_URL.split(':')) == 4:
        parts = PROXY_URL.split(':')
        ip, port, user, password = parts
        PROXY_URL = f"http://{user}:{password}@{ip}:{port}"
    # –ü–æ–¥–¥–µ—Ä–∂–∫–∞ —Ñ–æ—Ä–º–∞—Ç–∞ USER:PASS@IP:PORT (–±–µ–∑ –ø—Ä–æ—Ç–æ–∫–æ–ª–∞)
    elif "@" in PROXY_URL:
        PROXY_URL = f"http://{PROXY_URL}"
    # –û–±—ã—á–Ω—ã–π IP:PORT
    else:
        PROXY_URL = f"http://{PROXY_URL}"

# –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ñ–æ—Ä–º–∞—Ç–∞ –ø—Ä–æ–∫—Å–∏
if PROXY_URL and not PROXY_URL.startswith(("http://", "https://", "socks5://")):
    print(f"‚ö†Ô∏è –§–æ—Ä–º–∞—Ç PROXY_URL –Ω–µ –æ–ø–æ–∑–Ω–∞–Ω. –¢–µ–∫—É—â–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ: {PROXY_URL}")
    PROXY_URL = ""

# –ò—Å–ø–æ–ª—å–∑—É–µ–º –æ–¥–Ω—É —Å–µ—Å—Å–∏—é –Ω–∞ –≤–µ—Å—å –∑–∞–ø—É—Å–∫ (cookies + keep-alive)
SESSION = requests.Session()
SESSION.headers.update({
    "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8",
    "Accept-Language": "ru-RU,ru;q=0.9,en-US;q=0.8,en;q=0.7",
    "Cache-Control": "no-cache",
    "Connection": "keep-alive",
    "Upgrade-Insecure-Requests": "1",
})

if PROXY_URL:
    print(f"üåê –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–æ–∫—Å–∏: {PROXY_URL.split('@')[-1] if '@' in PROXY_URL else PROXY_URL}")
    SESSION.proxies = {"http": PROXY_URL, "https": PROXY_URL}


def warm_up_avito() -> bool:
    """–ü—Ä–æ–≥—Ä–µ—Ç—å —Å–µ—Å—Å–∏—é: –ø–æ–ª—É—á–∏—Ç—å –±–∞–∑–æ–≤—ã–µ cookies —Å –≥–ª–∞–≤–Ω–æ–π.

    –ï—Å–ª–∏ GitHub Actions IP –∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω, —á–∞—Å—Ç–æ 429 –ø—Ä–∏—Ö–æ–¥–∏—Ç —É–∂–µ —Ç—É—Ç.
    """
    try:
        headers = {
            "User-Agent": random.choice(USER_AGENTS),
            "Referer": AVITO_HOME_URL,
        }
        resp = SESSION.get(AVITO_HOME_URL, headers=headers, timeout=30)
        if resp.status_code == 429:
            print("\n‚ùå Avito –≤–µ—Ä–Ω—É–ª 429 –¥–∞–∂–µ –Ω–∞ –≥–ª–∞–≤–Ω–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü–µ ‚Äî –ø–æ—Ö–æ–∂–µ, IP —Å—Ä–µ–¥—ã –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –æ–≥—Ä–∞–Ω–∏—á–µ–Ω.")
            return False
        return True
    except requests.RequestException as e:
        print(f"\n‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ–≥—Ä–µ—Ç—å —Å–µ—Å—Å–∏—é Avito: {e}")
        # –ù–µ –±–ª–æ–∫–∏—Ä—É–µ–º –∑–∞–ø—É—Å–∫ –ø–æ–ª–Ω–æ—Å—Ç—å—é –∏–∑-–∑–∞ —Å–µ—Ç–µ–≤–æ–π –æ—à–∏–±–∫–∏
        return True


def load_urls_config() -> dict:
    """–ó–∞–≥—Ä—É–∑–∏—Ç—å —Ç–∞–±–ª–∏—Ü—É URL –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞"""
    if not URLS_FILE.exists():
        print(f"‚ùå –§–∞–π–ª {URLS_FILE} –Ω–µ –Ω–∞–π–¥–µ–Ω!")
        return {"entries": []}
    
    with open(URLS_FILE, 'r', encoding='utf-8') as f:
        return json.load(f)


def extract_price(price_text: str) -> Optional[int]:
    """–ò–∑–≤–ª–µ—á—å —Ü–µ–Ω—É –∏–∑ —Ç–µ–∫—Å—Ç–∞"""
    if not price_text:
        return None
    
    # –£–¥–∞–ª—è–µ–º –≤—Å–µ –∫—Ä–æ–º–µ —Ü–∏—Ñ—Ä
    digits = re.sub(r'[^\d]', '', price_text)
    if not digits:
        return None
    
    price = int(digits)
    
    # –§–∏–ª—å—Ç—Ä—É–µ–º –Ω–µ—Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω—ã–µ —Ü–µ–Ω—ã –¥–ª—è MacBook
    if price < 20000 or price > 700000:
        return None
    
    return price


def parse_avito_page(url: str, page: int = 1) -> list[int]:
    """–°–ø–∞—Ä—Å–∏—Ç—å –æ–¥–Ω—É —Å—Ç—Ä–∞–Ω–∏—Ü—É Avito –∏ –≤–µ—Ä–Ω—É—Ç—å —Å–ø–∏—Å–æ–∫ —Ü–µ–Ω"""
    prices = []
    
    # –î–æ–±–∞–≤–ª—è–µ–º –Ω–æ–º–µ—Ä —Å—Ç—Ä–∞–Ω–∏—Ü—ã –∫ URL
    page_url = url
    if page > 1:
        separator = '&' if '?' in url else '?'
        page_url = f"{url}{separator}p={page}"
    
    max_retries = 3
    base_retry_delay = 15  # –±–∞–∑–æ–≤–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞ –ø—Ä–∏ 429
    retry_delay_cap = 90   # –≤–µ—Ä—Ö–Ω–∏–π –ø—Ä–µ–¥–µ–ª –æ–∂–∏–¥–∞–Ω–∏—è, —á—Ç–æ–±—ã –Ω–µ "–≤–∏—Å–µ—Ç—å" –¥–µ—Å—è—Ç–∫–∏ –º–∏–Ω—É—Ç
    
    for attempt in range(max_retries):
        try:
            # –ó–∞–¥–µ—Ä–∂–∫–∞ –ø–µ—Ä–µ–¥ –∑–∞–ø—Ä–æ—Å–æ–º (–≤–∞–∂–Ω–æ!)
            delay = random.uniform(PAGE_DELAY_MIN, PAGE_DELAY_MAX)
            print(f"‚è≥ –ñ–¥—ë–º {delay:.1f}—Å...", end=" ", flush=True)
            time.sleep(delay)

            # –ó–∞–≥–æ–ª–æ–≤–∫–∏ —Å—Ç—Ä–æ–∏–º –Ω–∞ –∫–∞–∂–¥—ã–π –∑–∞–ø—Ä–æ—Å/–ø–æ–≤—Ç–æ—Ä (UA —Ä–æ—Ç—É–µ–º)
            headers = {
                "User-Agent": random.choice(USER_AGENTS),
                "Referer": AVITO_HOME_URL,
                "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8",
                "Accept-Language": "ru-RU,ru;q=0.9,en-US;q=0.8,en;q=0.7",
                "Cache-Control": "no-cache",
                "Upgrade-Insecure-Requests": "1",
            }

            response = SESSION.get(page_url, headers=headers, timeout=30)
            
            # –ï—Å–ª–∏ 429 (Too Many Requests), –∂–¥–µ–º –∏ –ø–æ–≤—Ç–æ—Ä—è–µ–º
            if response.status_code == 429:
                if CHANGE_IP_URL:
                    rotate_ip()
                
                if attempt < max_retries - 1:
                    retry_after = (response.headers.get("Retry-After") or "").strip()
                    if retry_after.isdigit():
                        wait_time = float(int(retry_after))
                    else:
                        wait_time = min(
                            retry_delay_cap,
                            base_retry_delay * (2 ** attempt) + random.uniform(5, 15),
                        )
                    print(f"\n    ‚ö†Ô∏è 429 –æ—à–∏–±–∫–∞, –∂–¥—ë–º {wait_time:.0f}—Å (–ø–æ–ø—ã—Ç–∫–∞ {attempt + 1}/{max_retries})...")
                    time.sleep(wait_time)
                    continue

                print(f"\n    ‚ùå 429 –ø–æ—Å–ª–µ {max_retries} –ø–æ–ø—ã—Ç–æ–∫, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º")
                return prices

            response.raise_for_status()
            
            soup = BeautifulSoup(response.text, 'lxml')
            
            # –ò—â–µ–º –∫–∞—Ä—Ç–æ—á–∫–∏ –æ–±—ä—è–≤–ª–µ–Ω–∏–π
            items = soup.select('[data-marker="item"]')
            
            if not items:
                # –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π —Å–µ–ª–µ–∫—Ç–æ—Ä
                items = soup.select('.iva-item-root')
            
            for item in items:
                try:
                    # –ò—â–µ–º —Ü–µ–Ω—É –≤ itemprop="price"
                    price_elem = item.select_one('[itemprop="price"]')
                    price = None
                    
                    if price_elem:
                        # –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–±—É–µ–º content –∞—Ç—Ä–∏–±—É—Ç
                        price_content = price_elem.get('content')
                        if price_content:
                            try:
                                if isinstance(price_content, list):
                                    price_content = price_content[0]
                                price = int(float(str(price_content)))
                            except (ValueError, TypeError):
                                pass
                        
                        # –ï—Å–ª–∏ –Ω–µ –ø–æ–ª—É—á–∏–ª–æ—Å—å, –ø–∞—Ä—Å–∏–º —Ç–µ–∫—Å—Ç
                        if not price:
                            price = extract_price(price_elem.get_text())
                    
                    # –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–µ —Å–µ–ª–µ–∫—Ç–æ—Ä—ã
                    if not price:
                        alt_price = item.select_one('[data-marker="item-price"]')
                        if alt_price:
                            price = extract_price(alt_price.get_text())
                    
                    if price:
                        prices.append(price)
                        
                except Exception:
                    continue
            
            # –£—Å–ø–µ—à–Ω–æ - –≤—ã—Ö–æ–¥–∏–º –∏–∑ —Ü–∏–∫–ª–∞ –ø–æ–≤—Ç–æ—Ä–æ–≤
            break
            
        except requests.RequestException as e:
            if attempt < max_retries - 1:
                wait_time = base_retry_delay * (attempt + 1)
                print(f"\n    ‚è≥ –û—à–∏–±–∫–∞ —Å–µ—Ç–∏, –∂–¥—ë–º {wait_time}—Å...")
                time.sleep(wait_time)
            else:
                print(f"\n    ‚ùå –û—à–∏–±–∫–∞: {e}")
    
    return prices


def load_fallback_buyout() -> dict:
    """–ó–∞–≥—Ä—É–∑–∏—Ç—å —Ç–∞–±–ª–∏—Ü—É –ú–æ–¥–µ–ª—å–Ω—ã–π —Ä—è–¥ –¥–ª—è fallback"""
    if not BUYOUT_FILE.exists():
        return {}
    
    try:
        with open(BUYOUT_FILE, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        # –°–æ–∑–¥–∞–µ–º —Å–ª–æ–≤–∞—Ä—å –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –ø–æ–∏—Å–∫–∞: (model, ram, storage) -> basePrice
        lookup = {}
        for item in data:
            model = item.get("model", "")
            ram = str(item.get("ram", ""))
            storage = str(item.get("storage", ""))
            base_price = item.get("basePrice", 0)
            if model and base_price:
                key = (model.lower(), ram, storage)
                # –ë–µ—Ä–µ–º –º–∞–∫—Å–∏–º–∞–ª—å–Ω—É—é —Ü–µ–Ω—É –µ—Å–ª–∏ –µ—Å—Ç—å –¥—É–±–ª–∏
                lookup[key] = max(lookup.get(key, 0), base_price)
        
        return lookup
    except Exception as e:
        print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ buyout.json: {e}")
        return {}


def find_fallback_price(lookup: dict, model_name: str, ram: int, ssd: int) -> Optional[int]:
    """–ù–∞–π—Ç–∏ —Ü–µ–Ω—É –≤ —Ç–∞–±–ª–∏—Ü–µ –ú–æ–¥–µ–ª—å–Ω—ã–π —Ä—è–¥"""
    key = (model_name.lower(), str(ram), str(ssd))
    return lookup.get(key)


def analyze_prices_iqr(prices: list[int]) -> tuple[int, int, int, int]:
    """
    –ê–Ω–∞–ª–∏–∑ —Ü–µ–Ω —Å —Ñ–æ–∫—É—Å–æ–º –Ω–∞ –ø–ª–æ—Ç–Ω–æ—Å—Ç—å (IQR).
    
    –ê–ª–≥–æ—Ä–∏—Ç–º:
    1. –£–±–∏—Ä–∞–µ–º –∫—Ä–∞–π–Ω–∏–µ 10% (–≤—ã–±—Ä–æ—Å—ã)
    2. –ù–∞—Ö–æ–¥–∏–º IQR (25-75 –ø–µ—Ä—Ü–µ–Ω—Ç–∏–ª—å) - –∑–æ–Ω—É –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π –ø–ª–æ—Ç–Ω–æ—Å—Ç–∏
    3. –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è —Ü–µ–Ω–∞ - Q1 (25 –ø–µ—Ä—Ü–µ–Ω—Ç–∏–ª—å) –∏–∑ —ç—Ç–æ–π –∑–æ–Ω—ã
    4. –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è —Ü–µ–Ω–∞ - Q3 (75 –ø–µ—Ä—Ü–µ–Ω—Ç–∏–ª—å)
    5. –ú–µ–¥–∏–∞–Ω–∞ –±–µ—Ä–µ—Ç—Å—è —Å —É–∫–ª–æ–Ω–æ–º –≤ —Å—Ç–æ—Ä–æ–Ω—É –º–∏–Ω–∏–º—É–º–∞
    
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç: (min_price, max_price, median_price, dense_median)
    """
    prices_sorted = sorted(prices)
    n = len(prices_sorted)
    
    if n < 5:
        median = int(statistics.median(prices_sorted))
        return min(prices_sorted), max(prices_sorted), median, median
    
    # –®–∞–≥ 1: –£–±–∏—Ä–∞–µ–º 10% –∫—Ä–∞–π–Ω–∏—Ö –∑–Ω–∞—á–µ–Ω–∏–π (P10-P90)
    p10_idx = int(n * 0.10)
    p90_idx = max(p10_idx + 1, int(n * 0.90))
    filtered = prices_sorted[p10_idx:p90_idx + 1]
    
    if len(filtered) < 3:
        filtered = prices_sorted
    
    # –®–∞–≥ 2: –ù–∞—Ö–æ–¥–∏–º IQR (–∑–æ–Ω–∞ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π –ø–ª–æ—Ç–Ω–æ—Å—Ç–∏ 50%)
    fn = len(filtered)
    q1_idx = int(fn * 0.25)
    q3_idx = int(fn * 0.75)
    
    q1_price = filtered[q1_idx]  # 25 –ø–µ—Ä—Ü–µ–Ω—Ç–∏–ª—å - –Ω–∏–∂–Ω—è—è –≥—Ä–∞–Ω–∏—Ü–∞ –ø–ª–æ—Ç–Ω–æ–π –∑–æ–Ω—ã
    q3_price = filtered[q3_idx]  # 75 –ø–µ—Ä—Ü–µ–Ω—Ç–∏–ª—å - –≤–µ—Ä—Ö–Ω—è—è –≥—Ä–∞–Ω–∏—Ü–∞ –ø–ª–æ—Ç–Ω–æ–π –∑–æ–Ω—ã
    
    # –®–∞–≥ 3: –ú–µ–¥–∏–∞–Ω–∞ —Å —É–∫–ª–æ–Ω–æ–º –∫ –º–∏–Ω–∏–º—É–º—É (–±–ª–∏–∂–µ –∫ Q1)
    # –ë–µ—Ä–µ–º —Å—Ä–µ–¥–Ω–µ–µ –º–µ–∂–¥—É Q1 –∏ –º–µ–¥–∏–∞–Ω–æ–π
    true_median = int(statistics.median(filtered))
    dense_median = int((q1_price + true_median) / 2)
    
    print(f"     üìà –ê–Ω–∞–ª–∏–∑ –ø–ª–æ—Ç–Ω–æ—Å—Ç–∏:")
    print(f"        ‚Ä¢ –í—Å–µ–≥–æ —Ü–µ–Ω: {n}, –ø–æ—Å–ª–µ P10-P90: {len(filtered)}")
    print(f"        ‚Ä¢ –ü–æ–ª–Ω—ã–π –¥–∏–∞–ø–∞–∑–æ–Ω: {prices_sorted[0]:,} - {prices_sorted[-1]:,} ‚ÇΩ")
    print(f"        ‚Ä¢ –ó–æ–Ω–∞ –ø–ª–æ—Ç–Ω–æ—Å—Ç–∏ (IQR): {q1_price:,} - {q3_price:,} ‚ÇΩ")
    print(f"        ‚Ä¢ –ú–µ–¥–∏–∞–Ω–∞ —Ä—ã–Ω–∫–∞: {true_median:,} ‚ÇΩ")
    print(f"        ‚Ä¢ –†–∞–±–æ—á–∞—è —Ü–µ–Ω–∞ (—É–∫–ª–æ–Ω –∫ –º–∏–Ω): {dense_median:,} ‚ÇΩ")
    
    return q1_price, q3_price, true_median, dense_median


def calculate_buyout_price(market_price: int) -> int:
    """
    –†–∞—Å—á–µ—Ç —Ü–µ–Ω—ã –≤—ã–∫—É–ø–∞: -20% –æ—Ç —Ä—ã–Ω–æ—á–Ω–æ–π, –æ–∫—Ä—É–≥–ª–µ–Ω–∏–µ –¥–æ 1000‚ÇΩ
    """
    raw_price = market_price * 0.80
    rounded_price = round(raw_price / 1000) * 1000
    return int(rounded_price)


def parse_entry(entry: dict, pages_count: int = DEFAULT_PAGES, 
                fallback_lookup: Optional[dict] = None) -> Optional[PriceStat]:
    """–°–ø–∞—Ä—Å–∏—Ç—å –æ–¥–Ω—É –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –∏–∑ —Ç–∞–±–ª–∏—Ü—ã"""
    model_name = entry.get("model_name", "")
    processor = entry.get("processor", "")
    ram = entry.get("ram", 0)
    ssd = entry.get("ssd", 0)
    url = entry.get("url", "")
    
    if not url:
        print(f"  ‚ö†Ô∏è –ü—Ä–æ–ø—É—Å–∫ {model_name} - –Ω–µ—Ç URL")
        return None
    
    print(f"\n{'='*60}")
    print(f"üîç {model_name} | {processor} | {ram}GB RAM | {ssd}GB SSD")
    print(f"{'='*60}")
    
    all_prices = []
    
    # –ü–∞—Ä—Å–∏–º –Ω–µ—Å–∫–æ–ª—å–∫–æ —Å—Ç—Ä–∞–Ω–∏—Ü
    for page in range(1, pages_count + 1):
        print(f"  üìÑ –°—Ç—Ä–∞–Ω–∏—Ü–∞ {page}/{pages_count}:", end=" ", flush=True)
        page_prices = parse_avito_page(url, page)
        print(f"‚úÖ {len(page_prices)} —Ü–µ–Ω")
        all_prices.extend(page_prices)
        
        # –ï—Å–ª–∏ –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ –º–∞–ª–æ –æ–±—ä—è–≤–ª–µ–Ω–∏–π, –ø—Ä–µ–∫—Ä–∞—â–∞–µ–º
        if len(page_prices) < 10:
            print(f"  ‚ÑπÔ∏è –ú–∞–ª–æ –æ–±—ä—è–≤–ª–µ–Ω–∏–π –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ, –ø—Ä–µ–∫—Ä–∞—â–∞–µ–º")
            break
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞: –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –ª–∏ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞?
    if len(all_prices) < MIN_SAMPLES_FOR_ANALYSIS:
        print(f"  ‚ö†Ô∏è –ú–∞–ª–æ –¥–∞–Ω–Ω—ã—Ö ({len(all_prices)} < {MIN_SAMPLES_FOR_ANALYSIS})")
        
        # –ü—Ä–æ–±—É–µ–º fallback –Ω–∞ —Ç–∞–±–ª–∏—Ü—É "–ú–æ–¥–µ–ª—å–Ω—ã–π —Ä—è–¥"
        if fallback_lookup:
            fallback_price = find_fallback_price(fallback_lookup, model_name, ram, ssd)
            if fallback_price:
                print(f"  üìã –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ü–µ–Ω—É –∏–∑ —Ç–∞–±–ª–∏—Ü—ã –ú–æ–¥–µ–ª—å–Ω—ã–π —Ä—è–¥: {fallback_price:,} ‚ÇΩ")
                return PriceStat(
                    model_name=model_name,
                    processor=processor,
                    ram=ram,
                    ssd=ssd,
                    median_price=fallback_price,
                    min_price=fallback_price,
                    max_price=fallback_price,
                    buyout_price=fallback_price,  # –£–∂–µ –≥–æ—Ç–æ–≤–∞—è —Ü–µ–Ω–∞ –≤—ã–∫—É–ø–∞
                    samples_count=0,  # 0 = –¥–∞–Ω–Ω—ã–µ –∏–∑ fallback
                    updated_at=datetime.now().isoformat()
                )
        
        print(f"  ‚ùå –ù–µ—Ç fallback –¥–∞–Ω–Ω—ã—Ö, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º")
        return None
    
    # –ê–Ω–∞–ª–∏–∑ —Ü–µ–Ω —Å —Ñ–æ–∫—É—Å–æ–º –Ω–∞ –ø–ª–æ—Ç–Ω–æ—Å—Ç—å (IQR)
    min_price, max_price, median_price, dense_median = analyze_prices_iqr(all_prices)
    
    # –†–∞—Å—á–µ—Ç —Ü–µ–Ω—ã –≤—ã–∫—É–ø–∞: -20% –æ—Ç –ø–ª–æ—Ç–Ω–æ–π –º–µ–¥–∏–∞–Ω—ã, –æ–∫—Ä—É–≥–ª–µ–Ω–∏–µ –¥–æ 1000‚ÇΩ
    buyout_price = calculate_buyout_price(dense_median)
    
    print(f"\n  üìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã:")
    print(f"     ‚Ä¢ –°–æ–±—Ä–∞–Ω–æ: {len(all_prices)} –æ–±—ä—è–≤–ª–µ–Ω–∏–π")
    print(f"     ‚Ä¢ –î–∏–∞–ø–∞–∑–æ–Ω –ø–ª–æ—Ç–Ω–æ—Å—Ç–∏: {min_price:,} - {max_price:,} ‚ÇΩ")
    print(f"     ‚Ä¢ –†—ã–Ω–æ—á–Ω–∞—è —Ü–µ–Ω–∞: {dense_median:,} ‚ÇΩ")
    print(f"     ‚Ä¢ üí∞ –¶–µ–Ω–∞ –≤—ã–∫—É–ø–∞ (-20%): {buyout_price:,} ‚ÇΩ")
    
    return PriceStat(
        model_name=model_name,
        processor=processor,
        ram=ram,
        ssd=ssd,
        median_price=dense_median,  # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø–ª–æ—Ç–Ω—É—é –º–µ–¥–∏–∞–Ω—É
        min_price=min_price,
        max_price=max_price,
        buyout_price=buyout_price,
        samples_count=len(all_prices),
        updated_at=datetime.now().isoformat()
    )


def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –ø–∞—Ä—Å–µ—Ä–∞"""
    # –ü–æ–ª—É—á–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–∞–Ω–∏—Ü –∏–∑ –∞—Ä–≥—É–º–µ–Ω—Ç–æ–≤ –∏–ª–∏ –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π –æ–∫—Ä—É–∂–µ–Ω–∏—è
    import sys
    pages_count = DEFAULT_PAGES
    
    # –ò–∑ –∞—Ä–≥—É–º–µ–Ω—Ç–æ–≤ –∫–æ–º–∞–Ω–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–∏
    if len(sys.argv) > 1:
        try:
            pages_count = int(sys.argv[1])
        except ValueError:
            pass
    
    # –ò–∑ –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π –æ–∫—Ä—É–∂–µ–Ω–∏—è (–¥–ª—è GitHub Actions)
    env_pages = os.environ.get('PAGES')
    if env_pages:
        try:
            pages_count = int(env_pages)
        except ValueError:
            pass
    
    # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º —Ä–∞–∑—É–º–Ω—ã–º –¥–∏–∞–ø–∞–∑–æ–Ω–æ–º
    pages_count = max(1, min(pages_count, 5))
    
    print("=" * 70)
    print("üöÄ –ü–∞—Ä—Å–µ—Ä —Ü–µ–Ω MacBook —Å –ê–≤–∏—Ç–æ (–Ω–∞ –æ—Å–Ω–æ–≤–µ —Ç–∞–±–ª–∏—Ü—ã URL)")
    print(f"üìÖ {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"üìÑ –°—Ç—Ä–∞–Ω–∏—Ü –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞: {pages_count}")
    print(f"‚è±Ô∏è –ó–∞–¥–µ—Ä–∂–∫–∞ –º–µ–∂–¥—É —Å—Ç—Ä–∞–Ω–∏—Ü–∞–º–∏: {PAGE_DELAY_MIN:.0f}-{PAGE_DELAY_MAX:.0f}—Å")
    print(f"‚è±Ô∏è –ó–∞–¥–µ—Ä–∂–∫–∞ –º–µ–∂–¥—É –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è–º–∏: {CONFIG_DELAY_MIN:.0f}-{CONFIG_DELAY_MAX:.0f}—Å")
    print("=" * 70)
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º —Ç–∞–±–ª–∏—Ü—É URL
    config = load_urls_config()
    entries = config.get("entries", [])
    
    if not entries:
        print("\n‚ùå –ù–µ—Ç –∑–∞–ø–∏—Å–µ–π –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞!")
        print(f"   –î–æ–±–∞–≤—å—Ç–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –≤ —Ñ–∞–π–ª: {URLS_FILE}")
        
        # –°–æ–∑–¥–∞–µ–º –ø—É—Å—Ç–æ–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        result = {
            "generated_at": datetime.now().isoformat(),
            "total_listings": 0,
            "models": [],
            "stats": []
        }
        
        OUTPUT_FILE.parent.mkdir(parents=True, exist_ok=True)
        with open(OUTPUT_FILE, 'w', encoding='utf-8') as f:
            json.dump(result, f, ensure_ascii=False, indent=2)
        
        return
    
    print(f"\nüìã –ù–∞–π–¥–µ–Ω–æ {len(entries)} –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–π –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞")
    estimated_time = len(entries) * (pages_count * (PAGE_DELAY_MIN + PAGE_DELAY_MAX) / 2 + (CONFIG_DELAY_MIN + CONFIG_DELAY_MAX) / 2)
    print(f"‚è±Ô∏è –ü—Ä–∏–º–µ—Ä–Ω–æ–µ –≤—Ä–µ–º—è: {estimated_time / 60:.0f} –º–∏–Ω—É—Ç")

    # –ó–∞–≥—Ä—É–∂–∞–µ–º fallback —Ç–∞–±–ª–∏—Ü—É "–ú–æ–¥–µ–ª—å–Ω—ã–π —Ä—è–¥"
    fallback_lookup = load_fallback_buyout()
    if fallback_lookup:
        print(f"üìã –ó–∞–≥—Ä—É–∂–µ–Ω–∞ —Ç–∞–±–ª–∏—Ü–∞ –ú–æ–¥–µ–ª—å–Ω—ã–π —Ä—è–¥: {len(fallback_lookup)} –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–π –¥–ª—è fallback")
    else:
        print("‚ö†Ô∏è –¢–∞–±–ª–∏—Ü–∞ –ú–æ–¥–µ–ª—å–Ω—ã–π —Ä—è–¥ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞, fallback –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω")

    # –ü—Ä–æ–≥—Ä–µ–≤ —Å–µ—Å—Å–∏–∏ (cookies). –ï—Å–ª–∏ 429 –ø—Ä–∏—Ö–æ–¥–∏—Ç —Å—Ä–∞–∑—É ‚Äî –¥–∞–ª—å—à–µ –≤ GitHub Actions –æ–±—ã—á–Ω–æ –Ω–µ –∏–º–µ–µ—Ç —Å–º—ã—Å–ª–∞ –∂–¥–∞—Ç—å.
    if not warm_up_avito():
        if CHANGE_IP_URL:
            rotate_ip()
            if not warm_up_avito():
                raise SystemExit(2)
        else:
            raise SystemExit(2)

    # –ü–∞—Ä—Å–∏–º –∫–∞–∂–¥—É—é –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é
    stats = []
    total_listings = 0
    fallback_count = 0
    
    for i, entry in enumerate(entries, 1):
        print(f"\n\n{'#'*70}")
        print(f"# [{i}/{len(entries)}] –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è")
        print(f"{'#'*70}")
        
        stat = parse_entry(entry, pages_count=pages_count, fallback_lookup=fallback_lookup)
        if stat:
            stats.append(asdict(stat))
            if stat.samples_count == 0:
                fallback_count += 1
            else:
                total_listings += stat.samples_count
        
        # –ë–æ–ª—å—à–∞—è –ø–∞—É–∑–∞ –º–µ–∂–¥—É –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è–º–∏ (–∫—Ä–æ–º–µ –ø–æ—Å–ª–µ–¥–Ω–µ–π)
        if i < len(entries):
            delay = random.uniform(CONFIG_DELAY_MIN, CONFIG_DELAY_MAX)
            print(f"\n‚è∏Ô∏è –ü–∞—É–∑–∞ {delay:.0f}—Å –ø–µ—Ä–µ–¥ —Å–ª–µ–¥—É—é—â–µ–π –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–µ–π...")
            time.sleep(delay)
    
    # –§–æ—Ä–º–∏—Ä—É–µ–º —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ –º–æ–¥–µ–ª–∏
    unique_models = sorted(set(s["model_name"] for s in stats))
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
    result = {
        "generated_at": datetime.now().isoformat(),
        "total_listings": total_listings,
        "models": unique_models,
        "stats": stats
    }
    
    OUTPUT_FILE.parent.mkdir(parents=True, exist_ok=True)
    with open(OUTPUT_FILE, 'w', encoding='utf-8') as f:
        json.dump(result, f, ensure_ascii=False, indent=2)
    
    print("\n\n" + "=" * 70)
    print("‚úÖ –ì–û–¢–û–í–û!")
    print("=" * 70)
    print(f"   üìä –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–π: {len(stats)}/{len(entries)}")
    print(f"   üìà –í—Å–µ–≥–æ –æ–±—ä—è–≤–ª–µ–Ω–∏–π (Avito): {total_listings:,}")
    print(f"   üìã –ò–∑ —Ç–∞–±–ª–∏—Ü—ã –ú–æ–¥–µ–ª—å–Ω—ã–π —Ä—è–¥: {fallback_count}")
    print(f"   üè∑Ô∏è –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π: {len(unique_models)}")
    print(f"   üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤: {OUTPUT_FILE}")
    print("=" * 70)


if __name__ == "__main__":
    main()
