#!/usr/bin/env python3
import json
import os
import re
import time
import random
import statistics
from pathlib import Path
from dataclasses import dataclass, asdict
import requests
from bs4 import BeautifulSoup

# –ü—É—Ç–∏
SCRIPT_DIR = Path(__file__).parent
URLS_FILE = SCRIPT_DIR / "../../public/data/avito-urls.json"
OUTPUT_FILE = SCRIPT_DIR / "../../public/data/avito-prices.json"

# –£—Å–∫–æ—Ä–µ–Ω–Ω—ã–µ –∑–∞–¥–µ—Ä–∂–∫–∏
PAGE_DELAY = (3.0, 6.0)
CONFIG_DELAY = (10.0, 20.0)

@dataclass
class PriceStat:
    model_name: str
    processor: str
    ram: int
    ssd: int
    median_price: int
    buyout_price: int
    samples_count: int
    updated_at: str

def get_market_low(prices: list[int]) -> int:
    """–¢–≤–æ—è –º–µ—Ç–æ–¥–∏–∫–∞: –ù–∞—Ö–æ–¥–∏–º –Ω–∞—á–∞–ª–æ –ø–ª–æ—Ç–Ω–æ—Å—Ç–∏ –≤ –¥–µ—à–µ–≤–æ–º —Å–µ–≥–º–µ–Ω—Ç–µ"""
    if not prices: return 0
    prices = sorted(prices)
    n = len(prices)
    if n < 5: return int(statistics.median(prices))
    
    # 1. –û—Ç—Å–µ–∫–∞–µ–º –ø–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω–æ –¥–µ—à–µ–≤—ã–µ (–Ω–∏–∂–Ω–∏–µ 10% - –∑–∞–ø—á–∞—Å—Ç–∏/—Å–∫–∞–º)
    clean_prices = prices[int(n*0.1):]
    
    # 2. –ë–µ—Ä–µ–º —Ü–µ–Ω—É –Ω–∞ —É—Ä–æ–≤–Ω–µ 20% –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ —Å–ø–∏—Å–∫–∞ (—ç—Ç–æ –∏ –µ—Å—Ç—å –Ω–∞—á–∞–ª–æ '–ø–æ–ª–∫–∏' —Ü–µ–Ω)
    idx = int(len(clean_prices) * 0.2)
    return clean_prices[idx]

def parse_config(entry):
    url = entry['url']
    prices = []
    print(f"üîé –ê–Ω–∞–ª–∏–∑: {entry['model_name']} {entry['ram']}/{entry['ssd']}...")
    
    for page in range(1, 3): # 2 —Å—Ç—Ä–∞–Ω–∏—Ü—ã –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Ä—ã–Ω–∫–∞
        try:
            time.sleep(random.uniform(*PAGE_DELAY))
            resp = requests.get(url + f"&p={page}", timeout=20)
            if resp.status_code != 200: break
            soup = BeautifulSoup(resp.text, 'lxml')
            items = soup.select('[data-marker="item"]')
            for item in items:
                p_tag = item.select_one('[itemprop="price"]')
                if p_tag:
                    p = int(p_tag['content'])
                    if 20000 < p < 800000: prices.append(p)
            if len(items) < 15: break
        except: break
    
    if len(prices) < 5: return None
    
    market_low = get_market_low(prices)
    # –¢–≤–æ—è —Ñ–æ—Ä–º—É–ª–∞: —Ç–æ—á–∫–∞ –ø–ª–æ—Ç–Ω–æ—Å—Ç–∏ –º–∏–Ω—É—Å 12–∫
    buyout = int((market_low - 12000) // 1000 * 1000)
    
    return PriceStat(
        model_name=entry['model_name'], processor=entry['processor'],
        ram=entry['ram'], ssd=entry['ssd'],
        median_price=market_low, buyout_price=buyout,
        samples_count=len(prices), updated_at=time.ctime()
    )

def main():
    if not URLS_FILE.exists(): 
        print(f"‚ùå –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {URLS_FILE}")
        return
    
    with open(URLS_FILE, 'r') as f: 
        entries = json.load(f)['entries']
    
    # –ò–°–ü–†–ê–í–õ–ï–ù–ù–ê–Ø –õ–û–ì–ò–ö–ê –ë–ê–¢–ß–ï–ô
    batch_env = os.environ.get("BATCH", "1")
    
    if batch_env == "all":
        print("üì¶ –†–µ–∂–∏–º: –ü–∞—Ä—Å–∏–º –í–°–ï –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ —Å—Ä–∞–∑—É")
        my_entries = entries
    else:
        try:
            b_idx = int(batch_env)
            t_batches = int(os.environ.get("TOTAL_BATCHES", 3))
            chunk = len(entries) // t_batches
            # –ß—Ç–æ–±—ã –Ω–µ –±—ã–ª–æ –æ—à–∏–±–æ–∫ —Å –∏–Ω–¥–µ–∫—Å–∞–º–∏
            start = (b_idx - 1) * chunk
            end = b_idx * chunk if b_idx < t_batches else len(entries)
            my_entries = entries[start:end]
            print(f"üì¶ –†–µ–∂–∏–º: –ë–∞—Ç—á {b_idx} –∏–∑ {t_batches} (–∑–∞–ø–∏—Å–µ–π: {len(my_entries)})")
        except ValueError:
            print(f"‚ö†Ô∏è –ù–µ–≤–µ—Ä–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç BATCH ({batch_env}), –ø–∞—Ä—Å–∏–º –≤—Å—ë.")
            my_entries = entries

    new_stats = []
    for entry in my_entries:
        res = parse_config(entry)
        if res: new_stats.append(asdict(res))
        time.sleep(random.uniform(*CONFIG_DELAY))
        
    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ (—Å–ª–∏—è–Ω–∏–µ)
    data = {"stats": []}
    if OUTPUT_FILE.exists():
        try:
            with open(OUTPUT_FILE, 'r') as f: data = json.load(f)
        except: pass
        
    current = { (s['model_name'], s['ram'], s['ssd']): s for s in data['stats'] }
    for s in new_stats:
        current[(s['model_name'], s['ram'], s['ssd'])] = s
        
    OUTPUT_FILE.parent.mkdir(parents=True, exist_ok=True)
    with open(OUTPUT_FILE, 'w', encoding='utf-8') as f:
        json.dump({"updated_at": time.ctime(), "stats": list(current.values())}, f, ensure_ascii=False, indent=2)
    print(f"‚úÖ –ë–∞–∑–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∞. –í—Å–µ–≥–æ –≤ –±–∞–∑–µ: {len(current)} –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–π.")
