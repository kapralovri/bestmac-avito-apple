#!/usr/bin/env python3
"""
–ü–∞—Ä—Å–µ—Ä —Ü–µ–Ω MacBook —Å –ê–≤–∏—Ç–æ –¥–ª—è BestMac.ru
–°–æ–±–∏—Ä–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –æ —Ü–µ–Ω–∞—Ö –∏ –∞–≥—Ä–µ–≥–∏—Ä—É–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ –º–æ–¥–µ–ª—è–º.

–§–æ—Ä–º–∞—Ç –º–æ–¥–µ–ª–∏ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç –∫–∞—Ç–∞–ª–æ–≥—É –ê–≤–∏—Ç–æ:
  "MacBook Air 13 (2020, M1)"
  "MacBook Pro 14 (2023, M3 Pro)"

–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:
  python parser.py --output ../public/data/avito-prices.json

–¢—Ä–µ–±–æ–≤–∞–Ω–∏—è:
  pip install requests beautifulsoup4 lxml
"""

import argparse
import json
import re
import time
import random
from datetime import datetime, timedelta
from typing import Optional
from dataclasses import dataclass, asdict
from pathlib import Path

try:
    import requests
    from bs4 import BeautifulSoup
except ImportError:
    print("–£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏: pip install requests beautifulsoup4 lxml")
    exit(1)


@dataclass
class AvitoListing:
    """–û–±—ä—è–≤–ª–µ–Ω–∏–µ —Å –ê–≤–∏—Ç–æ"""
    title: str
    price: int
    url: str
    region: str
    published_date: Optional[str] = None


@dataclass
class ParsedMacbook:
    """–†–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω–∞—è –º–æ–¥–µ–ª—å MacBook"""
    model_name: str  # "MacBook Air 13 (2020, M1)"
    screen_size: int  # 13, 14, 15, 16
    year: int
    cpu: str  # "M1", "M2", "M3 Pro", "M4 Max", etc.
    ram: Optional[int] = None  # GB
    ssd: Optional[int] = None  # GB


@dataclass
class PriceStats:
    """–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Ü–µ–Ω –¥–ª—è –º–æ–¥–µ–ª–∏"""
    model_name: str      # "MacBook Air 13 (2020, M1)" - —Ñ–æ—Ä–º–∞—Ç –∫–∞—Ç–∞–ª–æ–≥–∞ –ê–≤–∏—Ç–æ
    ram: int
    ssd: int
    region: str
    median_price: int
    min_price: int
    max_price: int
    buyout_price: int
    samples_count: int
    updated_at: str


# –†–µ–≥–∏–æ–Ω—ã –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞
REGIONS = {
    "moskva": "–ú–æ—Å–∫–≤–∞",
    "moskovskaya_oblast": "–ú–æ—Å–∫–æ–≤—Å–∫–∞—è –æ–±–ª–∞—Å—Ç—å",
    "sankt-peterburg": "–°–∞–Ω–∫—Ç-–ü–µ—Ç–µ—Ä–±—É—Ä–≥",
}

# –ö–∞—Ç–∞–ª–æ–≥ –º–æ–¥–µ–ª–µ–π –ê–≤–∏—Ç–æ - –ø–æ–ª–Ω—ã–π —Å–ø–∏—Å–æ–∫ –¥–ª—è –ø–æ–∏—Å–∫–∞
# –§–æ—Ä–º–∞—Ç: (–ø–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å, —Ä–∞–∑–º–µ—Ä —ç–∫—Ä–∞–Ω–∞, –≥–æ–¥, –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä –∏–ª–∏ None –¥–ª—è Pro –±–µ–∑ –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–∞)
AVITO_MODELS = [
    # MacBook Air 13"
    ("macbook air 13 m1 2020", 13, 2020, "M1"),
    ("macbook air 13 m2 2022", 13, 2022, "M2"),
    ("macbook air 13 m3 2024", 13, 2024, "M3"),
    ("macbook air 13 m4 2025", 13, 2025, "M4"),
    
    # MacBook Air 15"
    ("macbook air 15 m2 2023", 15, 2023, "M2"),
    ("macbook air 15 m3 2024", 15, 2024, "M3"),
    ("macbook air 15 m4 2025", 15, 2025, "M4"),
    
    # MacBook Pro 13"
    ("macbook pro 13 m1 2020", 13, 2020, "M1"),
    ("macbook pro 13 m2 2022", 13, 2022, "M2"),
    
    # MacBook Pro 14" - –æ–±–æ–±—â–µ–Ω–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã –¥–ª—è –≤—Å–µ—Ö –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–æ–≤
    ("macbook pro 14 2021", 14, 2021, None),
    ("macbook pro 14 2023", 14, 2023, None),
    ("macbook pro 14 2024", 14, 2024, None),
    ("macbook pro 14 2025", 14, 2025, None),
    
    # MacBook Pro 16" - –æ–±–æ–±—â–µ–Ω–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã –¥–ª—è –≤—Å–µ—Ö –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–æ–≤
    ("macbook pro 16 2021", 16, 2021, None),
    ("macbook pro 16 2023", 16, 2023, None),
    ("macbook pro 16 2024", 16, 2024, None),
]

# User-Agent –¥–ª—è –∑–∞–ø—Ä–æ—Å–æ–≤
USER_AGENTS = [
    "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
    "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
    "Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:121.0) Gecko/20100101 Firefox/121.0",
]


def format_model_name(screen_size: int, year: int, cpu: Optional[str] = None, is_pro: bool = False) -> str:
    """–§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç –Ω–∞–∑–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ –≤ —Å—Ç–∏–ª–µ –∫–∞—Ç–∞–ª–æ–≥–∞ –ê–≤–∏—Ç–æ"""
    model_type = "MacBook Pro" if is_pro else "MacBook Air"
    if cpu:
        return f"{model_type} {screen_size} ({year}, {cpu})"
    else:
        return f"{model_type} {screen_size} ({year})"


def parse_price(text: str) -> Optional[int]:
    """–ò–∑–≤–ª–µ—á—å —Ü–µ–Ω—É –∏–∑ —Ç–µ–∫—Å—Ç–∞"""
    if not text:
        return None
    # –£–±–∏—Ä–∞–µ–º –≤—Å–µ –∫—Ä–æ–º–µ —Ü–∏—Ñ—Ä
    digits = re.sub(r'[^\d]', '', text)
    if digits:
        price = int(digits)
        # –§–∏–ª—å—Ç—Ä—É–µ–º –Ω–µ—Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω—ã–µ —Ü–µ–Ω—ã
        if 10000 <= price <= 500000:
            return price
    return None


def parse_ram(title: str) -> Optional[int]:
    """–ò–∑–≤–ª–µ—á—å RAM –∏–∑ –∑–∞–≥–æ–ª–æ–≤–∫–∞"""
    title_lower = title.lower()
    ram_match = re.search(r'(\d{1,2})\s*(gb|–≥–±)\s*(ram|–æ–∑—É|–ø–∞–º—è—Ç—å)?', title_lower)
    if ram_match:
        ram = int(ram_match.group(1))
        if ram in [8, 16, 18, 24, 32, 36, 48, 64, 96, 128]:
            return ram
    return None


def parse_ssd(title: str) -> Optional[int]:
    """–ò–∑–≤–ª–µ—á—å SSD –∏–∑ –∑–∞–≥–æ–ª–æ–≤–∫–∞"""
    title_lower = title.lower()
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º TB —Å–Ω–∞—á–∞–ª–∞ (1tb, 2tb, 4tb, 8tb)
    tb_match = re.search(r'(\d)\s*(tb|—Ç–±)', title_lower)
    if tb_match:
        tb_value = int(tb_match.group(1))
        ssd_gb = tb_value * 1024
        if ssd_gb in [1024, 2048, 4096, 8192]:  # 1TB, 2TB, 4TB, 8TB
            return ssd_gb
    
    # –ó–∞—Ç–µ–º GB (256gb, 512gb)
    gb_match = re.search(r'(\d{3,4})\s*(gb|–≥–±)\s*(ssd)?', title_lower)
    if gb_match:
        ssd = int(gb_match.group(1))
        if ssd in [256, 512]:  # —Ç–æ–ª—å–∫–æ 256GB –∏ 512GB
            return ssd
    
    return None


def fetch_avito_page(query: str, region: str, page: int = 1) -> list[AvitoListing]:
    """–ü–æ–ª—É—á–∏—Ç—å —Å—Ç—Ä–∞–Ω–∏—Ü—É –æ–±—ä—è–≤–ª–µ–Ω–∏–π —Å –ê–≤–∏—Ç–æ"""
    listings = []
    
    # –§–æ—Ä–º–∏—Ä—É–µ–º URL
    base_url = f"https://www.avito.ru/{region}/noutbuki"
    params = {
        'q': query,
        'p': page,
    }
    
    headers = {
        'User-Agent': random.choice(USER_AGENTS),
        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
        'Accept-Language': 'ru-RU,ru;q=0.9,en-US;q=0.8,en;q=0.7',
        'Connection': 'keep-alive',
        'Cache-Control': 'no-cache',
    }
    
    try:
        response = requests.get(base_url, params=params, headers=headers, timeout=15)
        response.raise_for_status()
        
        soup = BeautifulSoup(response.text, 'lxml')
        
        # –ò—â–µ–º –∫–∞—Ä—Ç–æ—á–∫–∏ –æ–±—ä—è–≤–ª–µ–Ω–∏–π
        items = soup.select('[data-marker="item"]')
        
        for item in items:
            try:
                # –ó–∞–≥–æ–ª–æ–≤–æ–∫
                title_elem = item.select_one('[itemprop="name"]')
                title = title_elem.get_text(strip=True) if title_elem else None
                
                # –¶–µ–Ω–∞
                price_elem = item.select_one('[itemprop="price"]')
                price = None
                if price_elem:
                    price_content = price_elem.get('content')
                    if price_content:
                        price = int(price_content)
                    else:
                        price = parse_price(price_elem.get_text())
                
                # –°—Å—ã–ª–∫–∞
                link_elem = item.select_one('a[itemprop="url"]')
                url = f"https://www.avito.ru{link_elem['href']}" if link_elem else None
                
                if title and price and url:
                    listings.append(AvitoListing(
                        title=title,
                        price=price,
                        url=url,
                        region=REGIONS.get(region, region),
                    ))
            except Exception as e:
                print(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ –∫–∞—Ä—Ç–æ—á–∫–∏: {e}")
                continue
                
    except requests.RequestException as e:
        print(f"–û—à–∏–±–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –¥–ª—è {query} –≤ {region}: {e}")
    
    return listings


def calculate_percentiles(prices: list[int], lower: float = 10, upper: float = 90) -> list[int]:
    """–û—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞—Ç—å –≤—ã–±—Ä–æ—Å—ã –ø–æ –ø–µ—Ä—Ü–µ–Ω—Ç–∏–ª—è–º"""
    if len(prices) < 5:
        return prices
    
    sorted_prices = sorted(prices)
    n = len(sorted_prices)
    lower_idx = int(n * lower / 100)
    upper_idx = int(n * upper / 100)
    
    return sorted_prices[lower_idx:upper_idx + 1]


def aggregate_prices(listings: list[AvitoListing], model_info: tuple) -> list[PriceStats]:
    """–ê–≥—Ä–µ–≥–∏—Ä–æ–≤–∞—Ç—å —Ü–µ–Ω—ã –ø–æ RAM –∏ SSD –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π –º–æ–¥–µ–ª–∏"""
    query, screen_size, year, cpu = model_info
    is_pro = 'pro' in query.lower() and 'air' not in query.lower()
    # –î–ª—è Pro –±–µ–∑ –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–∞ –ø–µ—Ä–µ–¥–∞–µ–º None, –¥–ª—è Air - –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä
    model_name = format_model_name(screen_size, year, cpu, is_pro)
    
    # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ RAM –∏ SSD
    groups: dict[tuple, list[int]] = {}
    
    for listing in listings:
        ram = parse_ram(listing.title) or 8  # –¥–µ—Ñ–æ–ª—Ç 8GB
        ssd = parse_ssd(listing.title) or 256  # –¥–µ—Ñ–æ–ª—Ç 256GB
        
        key = (model_name, ram, ssd, listing.region)
        
        if key not in groups:
            groups[key] = []
        groups[key].append(listing.price)
    
    # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
    stats = []
    for key, prices in groups.items():
        if len(prices) < 2:  # –º–∏–Ω–∏–º—É–º 2 –æ–±—ä—è–≤–ª–µ–Ω–∏—è
            continue
        
        # –û—á–∏—â–∞–µ–º –≤—ã–±—Ä–æ—Å—ã
        clean_prices = calculate_percentiles(prices)
        if not clean_prices:
            continue
        
        # –ú–µ–¥–∏–∞–Ω–∞
        sorted_prices = sorted(clean_prices)
        n = len(sorted_prices)
        median = sorted_prices[n // 2] if n % 2 else (sorted_prices[n // 2 - 1] + sorted_prices[n // 2]) // 2
        
        # –¶–µ–Ω–∞ –≤—ã–∫—É–ø–∞ (90% –æ—Ç –º–µ–¥–∏–∞–Ω—ã)
        buyout = int(median * 0.90)
        
        stats.append(PriceStats(
            model_name=key[0],
            ram=key[1],
            ssd=key[2],
            region=key[3],
            median_price=median,
            min_price=min(clean_prices),
            max_price=max(clean_prices),
            buyout_price=buyout,
            samples_count=len(prices),
            updated_at=datetime.now().isoformat(),
        ))
    
    return stats


def run_parser(output_path: str, max_pages: int = 2):
    """–ó–∞–ø—É—Å—Ç–∏—Ç—å –ø–∞—Ä—Å–µ—Ä"""
    print(f"üöÄ –ó–∞–ø—É—Å–∫ –ø–∞—Ä—Å–µ—Ä–∞ –ê–≤–∏—Ç–æ...")
    print(f"üìç –†–µ–≥–∏–æ–Ω—ã: {list(REGIONS.values())}")
    print(f"üì± –ú–æ–¥–µ–ª–µ–π –≤ –∫–∞—Ç–∞–ª–æ–≥–µ: {len(AVITO_MODELS)}")
    
    all_stats = []
    total_listings = 0
    
    for region_key, region_name in REGIONS.items():
        print(f"\nüìç –†–µ–≥–∏–æ–Ω: {region_name}")
        
        for model_info in AVITO_MODELS:
            query = model_info[0]
            print(f"  üîç {query}...", end=" ", flush=True)
            
            model_listings = []
            for page in range(1, max_pages + 1):
                listings = fetch_avito_page(query, region_key, page)
                model_listings.extend(listings)
                
                if not listings:
                    break
                
                # –ü–∞—É–∑–∞ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏ (3-7 —Å–µ–∫ —á—Ç–æ–±—ã –Ω–µ –∑–∞–±–∞–Ω–∏–ª–∏)
                time.sleep(random.uniform(3, 7))
            
            if model_listings:
                stats = aggregate_prices(model_listings, model_info)
                all_stats.extend(stats)
                total_listings += len(model_listings)
                print(f"–Ω–∞–π–¥–µ–Ω–æ {len(model_listings)} ‚Üí {len(stats)} –≥—Ä—É–ø–ø")
            else:
                print("0")
    
    print(f"\nüìä –í—Å–µ–≥–æ –æ–±—ä—è–≤–ª–µ–Ω–∏–π: {total_listings}")
    print(f"üìà –ê–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –∑–∞–ø–∏—Å–µ–π: {len(all_stats)}")
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º
    output = Path(output_path)
    output.parent.mkdir(parents=True, exist_ok=True)
    
    result = {
        "generated_at": datetime.now().isoformat(),
        "total_listings": total_listings,
        "models": sorted(list(set(s.model_name for s in all_stats))),  # —Ç–æ–ª—å–∫–æ –º–æ–¥–µ–ª–∏ —Å —Ä–µ–∞–ª—å–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏ –∏–∑ stats
        "stats": [asdict(s) for s in all_stats],
    }
    
    with open(output, 'w', encoding='utf-8') as f:
        json.dump(result, f, ensure_ascii=False, indent=2)
    
    print(f"‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤ {output_path}")
    return result


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="–ü–∞—Ä—Å–µ—Ä —Ü–µ–Ω MacBook —Å –ê–≤–∏—Ç–æ")
    parser.add_argument(
        "--output", 
        default="public/data/avito-prices.json",
        help="–ü—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è JSON"
    )
    parser.add_argument(
        "--pages",
        type=int,
        default=2,
        help="–ú–∞–∫—Å–∏–º—É–º —Å—Ç—Ä–∞–Ω–∏—Ü –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞"
    )
    
    args = parser.parse_args()
    run_parser(args.output, args.pages)
