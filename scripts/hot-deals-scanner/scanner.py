#!/usr/bin/env python3
import json
import os
import re
import time
import logging
import urllib3
from pathlib import Path
from urllib.parse import urljoin

# –û—Ç–∫–ª—é—á–∞–µ–º –≤–æ—Ä–Ω–∏–Ω–≥–∏
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

try:
    import requests
    from bs4 import BeautifulSoup
except ImportError:
    print("Error: Install requirements: pip install requests beautifulsoup4 lxml")
    exit(1)

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger("Scanner")

# –ü—É—Ç–∏
PRICES_FILE = Path("public/data/avito-prices.json")
SEEN_FILE = Path("public/data/seen-hot-deals.json")
TELEGRAM_URL = os.environ.get('TELEGRAM_NOTIFY_URL')

def extract_specs(text: str):
    """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç RAM –∏ SSD –∏–∑ –∑–∞–≥–æ–ª–æ–≤–∫–∞"""
    text = text.lower().replace(' ', '')
    # –ü–æ–∏—Å–∫ RAM
    ram = 8
    ram_m = re.search(r'(\d+)(?:gb|–≥–±)', text)
    if ram_m:
        val = int(ram_m.group(1))
        if val in [8, 16, 18, 24, 32, 36, 48, 64, 96, 128]: ram = val
    
    # –ü–æ–∏—Å–∫ SSD
    ssd = 256
    ssd_m = re.search(r'(\d+)(?:gb|–≥–±|tb|—Ç–±)', text)
    if ssd_m:
        val = int(ssd_m.group(1))
        if 'tb' in text or '—Ç–±' in text: ssd = val * 1024
        else: ssd = val
    return ram, ssd

class HotScanner:
    def __init__(self):
        self.prices = {}
        if PRICES_FILE.exists():
            try:
                with open(PRICES_FILE, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    for s in data.get('stats', []):
                        # –ö–ª—é—á –¥–ª—è –ø–æ–∏—Å–∫–∞: (–ú–æ–¥–µ–ª—å_–ª–æ–≤–µ—Ä, RAM, SSD)
                        key = (s['model_name'].lower().split('(')[0].strip(), s['ram'], s['ssd'])
                        self.prices[key] = s
                logger.info(f"‚úÖ –ë–∞–∑–∞ —Ü–µ–Ω –∑–∞–≥—Ä—É–∂–µ–Ω–∞: {len(self.prices)} –∫–æ–Ω—Ñ–∏–≥–æ–≤")
            except Exception as e:
                logger.error(f"‚ùå –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è —Ñ–∞–π–ª–∞ —Ü–µ–Ω: {e}")
        else:
            logger.warning("‚ö†Ô∏è –§–∞–π–ª avito-prices.json –Ω–µ –Ω–∞–π–¥–µ–Ω. –°–Ω–∞—á–∞–ª–∞ –∑–∞–ø—É—Å—Ç–∏—Ç–µ Parser!")

        self.seen = set()
        if SEEN_FILE.exists():
            try:
                with open(SEEN_FILE, 'r', encoding='utf-8') as f:
                    self.seen = set(json.load(f).get('seen_urls', []))
            except: pass

    def notify(self, title, price, market_low, buyout, ram, ssd, url):
        if not TELEGRAM_URL: return
        text = (
            f"üéØ <b>–ù–∞—à–µ–ª –≤–∞—Ä–∏–∞–Ω—Ç –ø–æ –ù–ò–ó–£ —Ä—ã–Ω–∫–∞!</b>\n\n"
            f"üíª {title}\n"
            f"‚öôÔ∏è –ö–æ–Ω—Ñ–∏–≥: <b>{ram}GB / {ssd}GB</b>\n"
            f"üí∞ –¶–µ–Ω–∞ —Å–µ–π—á–∞—Å: <b>{price:,} ‚ÇΩ</b>\n"
            f"üìâ –ù–∏–∑ —Ä—ã–Ω–∫–∞: {market_low:,} ‚ÇΩ\n"
            f"ü§ù –¢–≤–æ–π –≤—ã–∫—É–ø: {buyout:,} ‚ÇΩ\n\n"
            f"üîó <a href='{url}'>–û—Ç–∫—Ä—ã—Ç—å –æ–±—ä—è–≤–ª–µ–Ω–∏–µ</a>"
        )
        try:
            requests.post(TELEGRAM_URL, json={"text": text, "parse_mode": "HTML"}, timeout=10)
        except: pass

    def run(self):
        scan_url = os.environ.get('SCAN_URL')
        if not scan_url: return
        
        logger.info("üé¨ –ó–∞–ø—É—Å–∫ —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è...")
        try:
            headers = {"User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36"}
            resp = requests.get(scan_url, headers=headers, timeout=30)
            if resp.status_code != 200: return
            
            soup = BeautifulSoup(resp.text, 'lxml')
            items = soup.select('[data-marker="item"]')
            
            for item in items:
                try:
                    link_tag = item.select_one('[data-marker="item-title"]')
                    url = urljoin("https://www.avito.ru", link_tag['href'])
                    if url in self.seen: continue
                    
                    title = link_tag.get('title', '')
                    price_tag = item.select_one('[itemprop="price"]')
                    if not price_tag: continue
                    price = int(price_tag['content'])
                    
                    # –ò–∑–≤–ª–µ–∫–∞–µ–º —Å–ø–µ–∫–∏
                    ram, ssd = extract_specs(title)
                    
                    # –ò—â–µ–º —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
                    for (m_name, m_ram, m_ssd), stat in self.prices.items():
                        if m_name in title.lower() and m_ram == ram and m_ssd == ssd:
                            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ "–ù–∏–∑ —Ä—ã–Ω–∫–∞"
                            market_low = stat['median_price']
                            if price <= market_low * 0.97: # –ï—Å–ª–∏ —Ü–µ–Ω–∞ –Ω–∞ 3% –∏ –±–æ–ª–µ–µ –Ω–∏–∂–µ —Ç–≤–æ–µ–≥–æ "–ù–∏–∑–∞"
                                self.notify(title, price, market_low, stat['buyout_price'], ram, ssd, url)
                                self.seen.add(url)
                            break
                except: continue
                
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏—Å—Ç–æ—Ä–∏—é
            SEEN_FILE.parent.mkdir(parents=True, exist_ok=True)
            with open(SEEN_FILE, 'w', encoding='utf-8') as f:
                json.dump({"seen_urls": list(self.seen)[-3000:]}, f)
                
        except Exception as e:
            logger.error(f"üí• –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–∏: {e}")

if __name__ == "__main__":
    HotScanner().run()
