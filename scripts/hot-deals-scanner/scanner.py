#!/usr/bin/env python3
""" 
Hot Deals Scanner v2 (Avito)
–ò—Å–ø–æ–ª—å–∑—É–µ—Ç curl_cffi –¥–ª—è –æ–±—Ö–æ–¥–∞ TLS-–±–ª–æ–∫–∏—Ä–æ–≤–æ–∫ –∏ BeautifulSoup –¥–ª—è –Ω–∞–¥–µ–∂–Ω–æ–≥–æ –ø–∞—Ä—Å–∏–Ω–≥–∞.
"""
import json
import os
import re
import time
import random
import logging
from dataclasses import dataclass, asdict
from datetime import datetime
from typing import Optional, List, Set, Dict
from pathlib import Path
from urllib.parse import urljoin

# –°—Ç–æ—Ä–æ–Ω–Ω–∏–µ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ (–Ω—É–∂–Ω–æ —É—Å—Ç–∞–Ω–æ–≤–∏—Ç—å: pip install curl_cffi beautifulsoup4 lxml)
try:
    from curl_cffi import requests as cffi_requests
    HAS_CFFI = True
except ImportError:
    import requests as cffi_requests # Fallback, –Ω–æ –Ω–µ —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –¥–ª—è –ê–≤–∏—Ç–æ
    HAS_CFFI = False
    print("‚ö†Ô∏è –í–ù–ò–ú–ê–ù–ò–ï: curl_cffi –Ω–µ –Ω–∞–π–¥–µ–Ω. –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –æ–±—ã—á–Ω—ã–π requests. –í–æ–∑–º–æ–∂–Ω—ã –±–ª–æ–∫–∏—Ä–æ–≤–∫–∏ 403/429.")
    print("üëâ –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è —É—Å—Ç–∞–Ω–æ–≤–∏—Ç—å: pip install curl_cffi")

from bs4 import BeautifulSoup

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - [%(levelname)s] - %(message)s',
    datefmt='%H:%M:%S'
)
logger = logging.getLogger("AvitoScanner")

# --- –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø ---
DEFAULT_SCAN_URL = "https://www.avito.ru/moskva_i_mo/noutbuki/apple/b_u-ASgBAgICAkTwvA2I0jSo5A302WY?cd=1&f=ASgBAQICAkTwvA2I0jSo5A302WYBQJ7kDdTIn7YVvLGeFajjlxXCmZYVsNjvEdTY7xGc2O8RsqPEEZKjxBGOza0QmM2tEKaaxhDWzK0Q&localPriority=1&q=macbook&s=104"
SCAN_URL = os.environ.get('SCAN_URL', DEFAULT_SCAN_URL)
TELEGRAM_URL = os.environ.get('TELEGRAM_NOTIFY_URL') # URL –≤–µ–±—Ö—É–∫–∞ –∏–ª–∏ API
PROXY_URL = os.environ.get('PROXY_URL') # —Ñ–æ—Ä–º–∞—Ç: http://user:pass@host:port
PROXY_CHANGE_IP_URL = os.environ.get('PROXY_CHANGE_IP_URL') # –°—Å—ã–ª–∫–∞ –¥–ª—è —Ä–æ—Ç–∞—Ü–∏–∏ IP

HOT_DEAL_THRESHOLD = 0.90  # –ò—Å–∫–∞—Ç—å —Å–∫–∏–¥–∫—É 10% –∏ –±–æ–ª–µ–µ
PRICES_FILE = Path("public/data/avito-prices.json")
SEEN_DEALS_FILE = Path("public/data/seen-hot-deals.json")

# –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –∑–∞–ø—Ä–æ—Å–æ–≤
IMPERSONATE = "chrome120" # –ú–∞—Å–∫–∏—Ä–æ–≤–∫–∞ –ø–æ–¥ Chrome 120
TIMEOUT = 30
MAX_RETRIES = 3

@dataclass
class HotDeal:
    url: str
    title: str
    price: int
    median_price: int
    discount_percent: float
    model: str
    found_at: str

class AvitoScanner:
    def __init__(self):
        self.session = cffi_requests.Session()
        self.prices_db = self._load_prices()
        self.seen_deals = self._load_seen()
        
    def _load_prices(self) -> Dict[str, int]:
        """–ó–∞–≥—Ä—É–∑–∫–∞ –±–∞–∑—ã —Ü–µ–Ω"""
        if not PRICES_FILE.exists():
            logger.warning(f"‚ö†Ô∏è –ë–∞–∑–∞ —Ü–µ–Ω –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {PRICES_FILE}")
            return {}
        try:
            with open(PRICES_FILE, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            prices = {}
            for stat in data.get('stats', []):
                name = stat.get('model_name')
                median = stat.get('median_price')
                if name and median:
                    # –õ–æ–≥–∏–∫–∞: –±–µ—Ä–µ–º –º–∏–Ω–∏–º–∞–ª—å–Ω—É—é –º–µ–¥–∏–∞–Ω—É, –µ—Å–ª–∏ –º–æ–¥–µ–ª—å –¥—É–±–ª–∏—Ä—É–µ—Ç—Å—è
                    if name not in prices or median < prices[name]:
                        prices[name] = median
            logger.info(f"üìä –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(prices)} –º–æ–¥–µ–ª–µ–π —Ü–µ–Ω")
            return prices
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è –±–∞–∑—ã —Ü–µ–Ω: {e}")
            return {}

    def _load_seen(self) -> Set[str]:
        """–ó–∞–≥—Ä—É–∑–∫–∞ –∏—Å—Ç–æ—Ä–∏–∏ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã—Ö"""
        if not SEEN_DEALS_FILE.exists():
            return set()
        try:
            with open(SEEN_DEALS_FILE, 'r', encoding='utf-8') as f:
                return set(json.load(f).get('seen_urls', []))
        except Exception:
            return set()

    def _save_seen(self):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏—Å—Ç–æ—Ä–∏–∏"""
        try:
            SEEN_DEALS_FILE.parent.mkdir(parents=True, exist_ok=True)
            # –û—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 2000, —á—Ç–æ–±—ã —Ñ–∞–π–ª –Ω–µ —Ä–∞—Å–ø—É—Ö–∞–ª
            keep_urls = list(self.seen_deals)[-2000:]
            with open(SEEN_DEALS_FILE, 'w', encoding='utf-8') as f:
                json.dump({'updated_at': datetime.now().isoformat(), 'seen_urls': keep_urls}, f)
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è seen_deals: {e}")

    def _rotate_ip(self):
        """–õ–æ–≥–∏–∫–∞ —Å–º–µ–Ω—ã IP"""
        if PROXY_CHANGE_IP_URL:
            try:
                logger.info("üîÑ –í—ã–∑–æ–≤ API —Å–º–µ–Ω—ã IP...")
                cffi_requests.get(PROXY_CHANGE_IP_URL, timeout=10)
                time.sleep(10) # –ñ–¥–µ–º –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è
            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ —Å–º–µ–Ω—ã IP: {e}")
        else:
            logger.info("‚è≥ –ü–∞—É–∑–∞ –¥–ª—è '–æ—Å—Ç—ã–≤–∞–Ω–∏—è' (–Ω–µ—Ç API —Å–º–µ–Ω—ã IP)...")
            time.sleep(random.uniform(20, 40))

    def get_page(self, url: str) -> Optional[str]:
        """–°–∫–∞—á–∏–≤–∞–Ω–∏–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã —Å –º–∞—Å–∫–∏—Ä–æ–≤–∫–æ–π"""
        proxies = {"http": PROXY_URL, "https": PROXY_URL} if PROXY_URL else None
        
        for attempt in range(MAX_RETRIES):
            try:
                # –ï—Å–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–µ–º curl_cffi
                if HAS_CFFI:
                    resp = self.session.get(
                        url, 
                        impersonate=IMPERSONATE, 
                        proxies=proxies, 
                        timeout=TIMEOUT,
                        allow_redirects=True
                    )
                else:
                    # –û–±—ã—á–Ω—ã–π requests (–Ω—É–∂–Ω—ã –∑–∞–≥–æ–ª–æ–≤–∫–∏)
                    headers = {
                        'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
                        'Accept-Language': 'ru-RU,ru;q=0.9',
                    }
                    resp = self.session.get(url, headers=headers, proxies=proxies, timeout=TIMEOUT)

                if resp.status_code == 200:
                    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ —Å–æ—Ñ—Ç-–±–∞–Ω (–∫–∞–ø—á—É –≤ –∫–æ–Ω—Ç–µ–Ω—Ç–µ)
                    if "firewall" in resp.text.lower() or "–¥–æ—Å—Ç—É–ø –æ–≥—Ä–∞–Ω–∏—á–µ–Ω" in resp.text.lower():
                        logger.warning("‚ö†Ô∏è –ü–æ–ª—É—á–µ–Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–∞ —Å –∫–∞–ø—á–µ–π (Soft Block)")
                        self._rotate_ip()
                        continue
                    return resp.text
                
                elif resp.status_code in [403, 429]:
                    logger.warning(f"‚ö†Ô∏è –ë–ª–æ–∫–∏—Ä–æ–≤–∫–∞ {resp.status_code}. –ú–µ–Ω—è–µ–º IP...")
                    self._rotate_ip()
                    continue
                else:
                    logger.error(f"–û—à–∏–±–∫–∞ HTTP {resp.status_code}")
            
            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ —Å–µ—Ç–∏: {e}")
                time.sleep(5)
        
        return None

    def parse_listings(self, html: str) -> List[dict]:
        """–ü–∞—Ä—Å–∏–Ω–≥ —á–µ—Ä–µ–∑ BeautifulSoup"""
        soup = BeautifulSoup(html, 'lxml')
        items = []
        
        # –ê–≤–∏—Ç–æ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –∞—Ç—Ä–∏–±—É—Ç—ã data-marker –¥–ª—è —ç–ª–µ–º–µ–Ω—Ç–æ–≤
        # data-marker="item" - —Å–∞–º–æ –æ–±—ä—è–≤–ª–µ–Ω–∏–µ
        listing_blocks = soup.find_all('div', attrs={'data-marker': 'item'})
        
        for block in listing_blocks:
            try:
                # –°—Å—ã–ª–∫–∞ –∏ –Ω–∞–∑–≤–∞–Ω–∏–µ
                link_tag = block.find('a', attrs={'data-marker': 'item-title'})
                if not link_tag:
                    continue
                    
                title = link_tag.get('title', '').strip()
                href = link_tag.get('href', '')
                url = urljoin("https://www.avito.ru", href)
                
                # –¶–µ–Ω–∞
                price_meta = block.find('meta', attrs={'itemprop': 'price'})
                if price_meta:
                    price = int(price_meta.get('content', 0))
                else:
                    # Fallback –ø–æ–∏—Å–∫ —Ü–µ–Ω—ã —Ç–µ–∫—Å—Ç–æ–º
                    price_tag = block.find('p', attrs={'data-marker': 'item-price'})
                    if not price_tag:
                        # –ò–Ω–æ–≥–¥–∞ —Ü–µ–Ω–∞ –≤ –¥—Ä—É–≥–æ–º –±–ª–æ–∫–µ
                        price_tag = block.find('strong', class_=re.compile('styles-module-root'))
                    
                    price_text = price_tag.get_text() if price_tag else "0"
                    price = int(re.sub(r'\D', '', price_text) or 0)

                # –§–∏–ª—å—Ç—Ä —è–≤–Ω–æ–≥–æ –º—É—Å–æ—Ä–∞
                if price < 10000: 
                    continue
                    
                items.append({
                    'url': url,
                    'title': title,
                    'price': price
                })
                
            except Exception as e:
                continue
                
        logger.info(f"üì¶ –†–∞—Å–ø–∞—Ä—Å–µ–Ω–æ {len(items)} –æ–±—ä—è–≤–ª–µ–Ω–∏–π")
        return items

    def extract_model(self, title: str) -> Optional[str]:
        """–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –∏–∑ –∑–∞–≥–æ–ª–æ–≤–∫–∞"""
        t = title.lower()
        
        # –°–ª–æ–≤–∞—Ä—å –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤: (regex, model_name)
        # –ü–æ—Ä—è–¥–æ–∫ –≤–∞–∂–µ–Ω: –æ—Ç –±–æ–ª–µ–µ –¥–ª–∏–Ω–Ω—ã—Ö/—Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã—Ö –∫ –∫–æ—Ä–æ—Ç–∫–∏–º
        patterns = [
            (r'macbook\s*pro\s*16.*m4\s*max', 'MacBook Pro 16 (2024, M4 Max)'),
            (r'macbook\s*pro\s*16.*m4\s*pro', 'MacBook Pro 16 (2024, M4 Pro)'),
            (r'macbook\s*pro\s*16.*m3\s*max', 'MacBook Pro 16 (2023, M3 Max)'),
            (r'macbook\s*pro\s*16.*m3\s*pro', 'MacBook Pro 16 (2023, M3 Pro)'),
            (r'macbook\s*pro\s*16.*m2\s*max', 'MacBook Pro 16 (2023, M2 Max)'),
            (r'macbook\s*pro\s*16.*m2\s*pro', 'MacBook Pro 16 (2023, M2 Pro)'),
            (r'macbook\s*pro\s*16.*m1\s*max', 'MacBook Pro 16 (2021, M1 Max)'),
            (r'macbook\s*pro\s*16.*m1\s*pro', 'MacBook Pro 16 (2021, M1 Pro)'),
            
            (r'macbook\s*pro\s*14.*m3\s*max', 'MacBook Pro 14 (2023, M3 Max)'),
            (r'macbook\s*pro\s*14.*m3\s*pro', 'MacBook Pro 14 (2023, M3 Pro)'),
            (r'macbook\s*pro\s*14.*m3', 'MacBook Pro 14 (2023, M3)'),
            (r'macbook\s*pro\s*14.*m2', 'MacBook Pro 14 (2023, M2)'),
            (r'macbook\s*pro\s*14.*m1', 'MacBook Pro 14 (2021, M1)'),
            
            (r'macbook\s*pro\s*13.*m2', 'MacBook Pro 13 (2022, M2)'),
            (r'macbook\s*pro\s*13.*m1', 'MacBook Pro 13 (2020, M1)'),
            
            (r'macbook\s*air\s*15.*m3', 'MacBook Air 15 (2024, M3)'),
            (r'macbook\s*air\s*15.*m2', 'MacBook Air 15 (2023, M2)'),
            (r'macbook\s*air\s*13.*m3', 'MacBook Air 13 (2024, M3)'),
            (r'macbook\s*air\s*13.*m2', 'MacBook Air 13 (2022, M2)'),
            (r'macbook\s*air.*m1', 'MacBook Air 13 (2020, M1)'),
        ]
        
        for pattern, model in patterns:
            if re.search(pattern, t):
                return model
        return None

    def find_deals(self, listings: List[dict]) -> List[HotDeal]:
        deals = []
        for item in listings:
            if item['url'] in self.seen_deals:
                continue
                
            model = self.extract_model(item['title'])
            if not model:
                continue
                
            median = self.prices_db.get(model)
            if not median:
                continue
                
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ü–µ–Ω—ã
            # –ï—Å–ª–∏ —Ü–µ–Ω–∞ —Å–ª–∏—à–∫–æ–º –Ω–∏–∑–∫–∞—è (–Ω–∞–ø—Ä–∏–º–µ—Ä, < 40% –æ—Ç –º–µ–¥–∏–∞–Ω—ã), —ç—Ç–æ —á–∞—Å—Ç–æ —Å–∫–∞–º –∏–ª–∏ –∑–∞–ø—á–∞—Å—Ç–∏
            if item['price'] < (median * 0.4):
                continue
                
            threshold = median * HOT_DEAL_THRESHOLD
            
            if item['price'] <= threshold:
                discount = (1 - item['price'] / median) * 100
                deals.append(HotDeal(
                    url=item['url'],
                    title=item['title'],
                    price=item['price'],
                    median_price=median,
                    discount_percent=round(discount, 1),
                    model=model,
                    found_at=datetime.now().isoformat()
                ))
        return deals

    def send_notifications(self, deals: List[HotDeal]):
        if not deals:
            return

        logger.info(f"üöÄ –û—Ç–ø—Ä–∞–≤–∫–∞ {len(deals)} —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–π...")
        
        # –ï—Å–ª–∏ URL —Ç–µ–ª–µ–≥—Ä–∞–º–∞ –Ω–µ –∑–∞–¥–∞–Ω, –ø—Ä–æ—Å—Ç–æ –≤—ã–≤–æ–¥–∏–º –≤ –∫–æ–Ω—Å–æ–ª—å
        if not TELEGRAM_URL:
            for d in deals:
                print(f"üîî [SIMULATION] {d.model} –∑–∞ {d.price} (–°–∫–∏–¥–∫–∞ {d.discount_percent}%) -> {d.url}")
            return

        for deal in deals:
            try:
                # –§–æ—Ä–º–∏—Ä—É–µ–º –∫—Ä–∞—Å–∏–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
                text = (
                    f"üî• <b>HOT DEAL: {deal.model}</b>\n"
                    f"üí∞ –¶–µ–Ω–∞: <b>{deal.price:,} ‚ÇΩ</b>\n"
                    f"üìâ –ú–µ–¥–∏–∞–Ω–∞: {deal.median_price:,} ‚ÇΩ (–í—ã–≥–æ–¥–∞ {deal.discount_percent}%)\n"
                    f"üîó <a href='{deal.url}'>{deal.title}</a>"
                )
                
                payload = {
                    "text": text,
                    "parse_mode": "HTML",
                    "disable_web_page_preview": True
                }
                
                # –ó–¥–µ—Å—å –º–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –æ–±—ã—á–Ω—ã–π requests, —Ç.–∫. API Telegram –Ω–µ –±–ª–æ—á–∏—Ç
                cffi_requests.post(TELEGRAM_URL, json=payload, timeout=10)
                logger.info(f"‚úÖ –û—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ: {deal.title[:30]}")
                
            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏ —Ç–µ–ª–µ–≥—Ä–∞–º: {e}")

    def run(self):
        logger.info("üé¨ –ó–∞–ø—É—Å–∫ —Å–∫–∞–Ω–µ—Ä–∞...")
        if not self.prices_db:
            logger.error("‚ùå –ë–∞–∑–∞ —Ü–µ–Ω –ø—É—Å—Ç–∞, —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–µ–≤–æ–∑–º–æ–∂–Ω–æ.")
            return

        html = self.get_page(SCAN_URL)
        if html:
            listings = self.parse_listings(html)
            hot_deals = self.find_deals(listings)
            
            if hot_deals:
                logger.info(f"üî• –ù–∞–π–¥–µ–Ω–æ {len(hot_deals)} –≥–æ—Ä—è—á–∏—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π!")
                self.send_notifications(hot_deals)
                
                # –î–æ–±–∞–≤–ª—è–µ–º –≤ –ø—Ä–æ—Å–º–æ—Ç—Ä–µ–Ω–Ω—ã–µ
                for d in hot_deals:
                    self.seen_deals.add(d.url)
                self._save_seen()
            else:
                logger.info("ü§∑ –ì–æ—Ä—è—á–∏—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π –Ω–µ –Ω–∞–π–¥–µ–Ω–æ")
        else:
            logger.error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Å—Ç—Ä–∞–Ω–∏—Ü—É Avito")

if __name__ == "__main__":
    scanner = AvitoScanner()
    scanner.run()
