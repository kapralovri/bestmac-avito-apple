#!/usr/bin/env python3
"""
Hot Deals Scanner - —Å–∫–∞–Ω–∏—Ä—É–µ—Ç –ê–≤–∏—Ç–æ –∫–∞–∂–¥—ã–µ 15 –º–∏–Ω—É—Ç –Ω–∞ –ø—Ä–µ–¥–º–µ—Ç –≥–æ—Ä—è—á–∏—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π
–ü–∞—Ä—Å–∏—Ç –Ω–æ–≤—ã–µ –æ–±—ä—è–≤–ª–µ–Ω–∏—è –∏ —Å—Ä–∞–≤–Ω–∏–≤–∞–µ—Ç —Å –º–µ–¥–∏–∞–Ω–Ω—ã–º–∏ —Ü–µ–Ω–∞–º–∏ –∏–∑ –±–∞–∑—ã
"""

import json
import os
import re
import time
import random
import requests
from dataclasses import dataclass, asdict
from datetime import datetime
from typing import Optional
from pathlib import Path
import logging

logging.basicConfig(level=logging.DEBUG, format='%(asctime)s - %(levelname)s - %(message)s')

# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
# URL –º–æ–∂–Ω–æ –ø–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å —á–µ—Ä–µ–∑ env –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é SCAN_URL
DEFAULT_SCAN_URL = "https://www.avito.ru/moskva_i_mo/noutbuki/apple/b_u-ASgBAgICAkTwvA2I0jSo5A302WY?cd=1&f=ASgBAQICAkTwvA2I0jSo5A302WYBQJ7kDdTIn7YVvLGeFajjlxXCmZYVsNjvEdTY7xGc2O8RsqPEEZKjxBGOza0QmM2tEKaaxhDWzK0Q&localPriority=1&q=macbook&s=104"
SCAN_URL = os.environ.get('SCAN_URL', DEFAULT_SCAN_URL)
HOT_DEAL_THRESHOLD = 0.90  # 10% –Ω–∏–∂–µ –º–µ–¥–∏–∞–Ω—ã
PRICES_FILE = Path("public/data/avito-prices.json")
SEEN_DEALS_FILE = Path("public/data/seen-hot-deals.json")


@dataclass
class HotDeal:
    """–ì–æ—Ä—è—á–µ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ"""
    url: str
    title: str
    price: int
    median_price: int
    discount_percent: float
    model: str
    found_at: str


def load_prices_database() -> dict:
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –±–∞–∑—É –º–µ–¥–∏–∞–Ω–Ω—ã—Ö —Ü–µ–Ω"""
    if not PRICES_FILE.exists():
        print("‚ö†Ô∏è –ë–∞–∑–∞ —Ü–µ–Ω –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
        return {}
    
    with open(PRICES_FILE, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    # –°–æ–∑–¥–∞—ë–º —Å–ª–æ–≤–∞—Ä—å –¥–ª—è –ø–æ–∏—Å–∫–∞: model_name -> list of {ram, ssd, median_price}
    # –¢–∞–∫–∂–µ —Å–æ–∑–¥–∞—ë–º —É–ø—Ä–æ—â—ë–Ω–Ω—ã–π —Å–ª–æ–≤–∞—Ä—å model_name -> min median –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
    prices = {}
    
    # –ü–æ–ª–µ –Ω–∞–∑—ã–≤–∞–µ—Ç—Å—è 'stats', –Ω–µ 'statistics'
    for stat in data.get('stats', []):
        model_name = stat.get('model_name', '')
        median = stat.get('median_price')  # –ü–æ–ª–µ median_price, –Ω–µ median
        
        if model_name and median and median > 0:
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–∏–Ω–∏–º–∞–ª—å–Ω—É—é –º–µ–¥–∏–∞–Ω—É –¥–ª—è –º–æ–¥–µ–ª–∏ (–±–∞–∑–æ–≤–∞—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è)
            if model_name not in prices or median < prices[model_name]:
                prices[model_name] = median
    
    print(f"üìä –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(prices)} –º–æ–¥–µ–ª–µ–π –∏–∑ –±–∞–∑—ã —Ü–µ–Ω")
    if prices:
        print(f"   –ü—Ä–∏–º–µ—Ä—ã: {list(prices.items())[:3]}")
    return prices


def load_seen_deals() -> set:
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç —É–∂–µ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–µ —Å–¥–µ–ª–∫–∏"""
    if not SEEN_DEALS_FILE.exists():
        return set()
    
    try:
        with open(SEEN_DEALS_FILE, 'r', encoding='utf-8') as f:
            data = json.load(f)
            return set(data.get('seen_urls', []))
    except:
        return set()


def save_seen_deals(seen_urls: set):
    """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–µ —Å–¥–µ–ª–∫–∏"""
    # –•—Ä–∞–Ω–∏–º —Ç–æ–ª—å–∫–æ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 1000 URL
    urls_list = list(seen_urls)[-1000:]
    
    with open(SEEN_DEALS_FILE, 'w', encoding='utf-8') as f:
        json.dump({
            'updated_at': datetime.now().isoformat(),
            'seen_urls': urls_list
        }, f, ensure_ascii=False, indent=2)


def get_session() -> requests.Session:
    """–°–æ–∑–¥–∞—ë—Ç —Å–µ—Å—Å–∏—é —Å –ø—Ä–æ–∫—Å–∏"""
    session = requests.Session()
    logging.debug("–°–æ–∑–¥–∞–Ω–∏–µ —Å–µ—Å—Å–∏–∏ —Å –ø—Ä–æ–∫—Å–∏")

    def normalize_proxy_url(raw: str) -> str:
        raw = (raw or "").strip().strip('"').strip("'")
        logging.debug(f"–ò—Å—Ö–æ–¥–Ω—ã–π –ø—Ä–æ–∫—Å–∏ URL: {raw}")
        if not raw:
            logging.warning("–ü—Ä–æ–∫—Å–∏ URL –ø—É—Å—Ç–æ–π")
            return ""

        # –ü–æ–¥–¥–µ—Ä–∂–∫–∞ —Ñ–æ—Ä–º–∞—Ç–æ–≤
        if raw.startswith(("http://", "https://", "socks5://")):
            return raw
        parts = raw.split(":")
        if len(parts) == 4 and "@" not in raw:
            host, port, user, password = parts
            proxy_url = f"http://{user}:{password}@{host}:{port}"
            logging.debug(f"–ü—Ä–æ–∫—Å–∏ URL –ø–æ—Å–ª–µ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏: {proxy_url}")
            return proxy_url
        if "@" in raw:
            proxy_url = f"http://{raw}"
            logging.debug(f"–ü—Ä–æ–∫—Å–∏ URL –ø–æ—Å–ª–µ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏: {proxy_url}")
            return proxy_url
        proxy_url = f"http://{raw}"
        logging.debug(f"–ü—Ä–æ–∫—Å–∏ URL –ø–æ—Å–ª–µ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏: {proxy_url}")
        return proxy_url

    proxy_url_raw = os.environ.get('PROXY_URL', '45.153.73.189:11223:DalSdwuMhy:ebjGk5Zwxz')
    proxy_url = normalize_proxy_url(proxy_url_raw)
    logging.info(f"–ò—Å–ø–æ–ª—å–∑—É–µ–º—ã–π –ø—Ä–æ–∫—Å–∏ URL: {proxy_url}")

    session.proxies = {"http": proxy_url, "https": proxy_url}
    
    def change_ip():
        logging.info("Changing IP...")
        time.sleep(5)
        logging.info("IP changed")

    def warm_up_avito(session: requests.Session) -> bool:
        """–ü—Ä–æ–≥—Ä–µ–≤–∞–µ—Ç —Å–µ—Å—Å–∏—é: –ø–æ–ª—É—á–∞–µ—Ç cookies —Å –≥–ª–∞–≤–Ω–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã.

        –≠—Ç–æ —Å–Ω–∏–∂–∞–µ—Ç —à–∞–Ω—Å 302/–∫–∞–ø—á–∏ –Ω–∞ –ø–µ—Ä–≤–æ–º –∂–µ –∑–∞–ø—Ä–æ—Å–µ –∫ –≤—ã–¥–∞—á–µ.
        """
        try:
            resp = session.get('https://www.avito.ru/', timeout=(15, 45), allow_redirects=True)
            if resp.status_code in (200, 204):
                return True
            if resp.status_code in (403, 429):
                change_ip()
                return warm_up_avito(session)
            return True
        except requests.RequestException:
            return True

    warm_up_avito(session)
    
    return session


def extract_model_from_title(title: str) -> Optional[str]:
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –º–æ–¥–µ–ª—å MacBook –∏–∑ –∑–∞–≥–æ–ª–æ–≤–∫–∞"""
    title_lower = title.lower()
    
    # –ü–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –º–æ–¥–µ–ª–∏
    patterns = [
        # MacBook Pro —Å —á–∏–ø–∞–º–∏ M
        (r'macbook\s*pro\s*16.*m4\s*max', 'MacBook Pro 16 (2024, M4 Max)'),
        (r'macbook\s*pro\s*16.*m4\s*pro', 'MacBook Pro 16 (2024, M4 Pro)'),
        (r'macbook\s*pro\s*16.*m4', 'MacBook Pro 16 (2024, M4 Pro)'),
        (r'macbook\s*pro\s*14.*m4\s*max', 'MacBook Pro 14 (2024, M4 Max)'),
        (r'macbook\s*pro\s*14.*m4\s*pro', 'MacBook Pro 14 (2024, M4 Pro)'),
        (r'macbook\s*pro\s*14.*m4', 'MacBook Pro 14 (2024, M4)'),
        (r'macbook\s*pro\s*16.*m3\s*max', 'MacBook Pro 16 (2023, M3 Max)'),
        (r'macbook\s*pro\s*16.*m3\s*pro', 'MacBook Pro 16 (2023, M3 Pro)'),
        (r'macbook\s*pro\s*14.*m3\s*max', 'MacBook Pro 14 (2023, M3 Max)'),
        (r'macbook\s*pro\s*14.*m3\s*pro', 'MacBook Pro 14 (2023, M3 Pro)'),
        (r'macbook\s*pro\s*14.*m3', 'MacBook Pro 14 (2023, M3)'),
        (r'macbook\s*pro\s*16.*m2\s*max', 'MacBook Pro 16 (2023, M2 Max)'),
        (r'macbook\s*pro\s*16.*m2\s*pro', 'MacBook Pro 16 (2023, M2 Pro)'),
        (r'macbook\s*pro\s*14.*m2\s*max', 'MacBook Pro 14 (2023, M2 Max)'),
        (r'macbook\s*pro\s*14.*m2\s*pro', 'MacBook Pro 14 (2023, M2 Pro)'),
        (r'macbook\s*pro\s*16.*m1\s*max', 'MacBook Pro 16 (2021, M1 Max)'),
        (r'macbook\s*pro\s*16.*m1\s*pro', 'MacBook Pro 16 (2021, M1 Pro)'),
        (r'macbook\s*pro\s*14.*m1\s*max', 'MacBook Pro 14 (2021, M1 Max)'),
        (r'macbook\s*pro\s*14.*m1\s*pro', 'MacBook Pro 14 (2021, M1 Pro)'),
        (r'macbook\s*pro\s*13.*m2', 'MacBook Pro 13 (2022, M2)'),
        (r'macbook\s*pro\s*13.*m1', 'MacBook Pro 13 (2020, M1)'),
        
        # MacBook Air —Å —á–∏–ø–∞–º–∏ M
        (r'macbook\s*air\s*15.*m4', 'MacBook Air 15 (2025, M4)'),
        (r'macbook\s*air\s*13.*m4', 'MacBook Air 13 (2025, M4)'),
        (r'macbook\s*air\s*15.*m3', 'MacBook Air 15 (2024, M3)'),
        (r'macbook\s*air\s*13.*m3', 'MacBook Air 13 (2024, M3)'),
        (r'macbook\s*air\s*15.*m2', 'MacBook Air 15 (2023, M2)'),
        (r'macbook\s*air\s*13.*m2', 'MacBook Air 13 (2022, M2)'),
        (r'macbook\s*air.*m1', 'MacBook Air 13 (2020, M1)'),
    ]
    
    for pattern, model in patterns:
        if re.search(pattern, title_lower):
            return model
    
    return None


def parse_listings(session: requests.Session, max_retries: int = 5) -> list[dict]:
    """–ü–∞—Ä—Å–∏—Ç –æ–±—ä—è–≤–ª–µ–Ω–∏—è —Å–æ —Å—Ç—Ä–∞–Ω–∏—Ü—ã –ê–≤–∏—Ç–æ —Å retry-–ª–æ–≥–∏–∫–æ–π"""
    listings = []

    def looks_like_block(html_text: str) -> bool:
        t = (html_text or "").lower()
        return any(
            k in t
            for k in [
                "captcha",
                "–Ω–µ —Ä–æ–±–æ—Ç",
                "–ø–æ–¥—Ç–≤–µ—Ä–¥–∏—Ç–µ",
                "–¥–æ—Å—Ç—É–ø –æ–≥—Ä–∞–Ω–∏—á–µ–Ω",
                "blocked",
                "security",
            ]
        )

    # –ü—Ä–æ–≥—Ä–µ–≤ (–æ–¥–∏–Ω —Ä–∞–∑ –ø–µ—Ä–µ–¥ –ø–æ–ø—ã—Ç–∫–∞–º–∏)
    warm_up_avito(session)
    
    for attempt in range(max_retries):
        try:
            print(f"üîç –°–∫–∞–Ω–∏—Ä—É—é (–ø–æ–ø—ã—Ç–∫–∞ {attempt + 1}/{max_retries}): {SCAN_URL[:70]}...")
            
            # –î–æ–±–∞–≤–ª—è–µ–º —Ä–∞–Ω–¥–æ–º–Ω—É—é –∑–∞–¥–µ—Ä–∂–∫—É
            time.sleep(random.uniform(3, 7))
            
            # –ù–µ–±–æ–ª—å—à–æ–π cache-busting, —á—Ç–æ–±—ã –Ω–µ –ª–æ–≤–∏—Ç—å –æ–¥–∏–Ω–∞–∫–æ–≤—ã–µ –æ—Ç–≤–µ—Ç—ã/–∫–µ—à —É –ø—Ä–æ–∫—Å–∏
            separator = '&' if '?' in SCAN_URL else '?'
            scan_url = f"{SCAN_URL}{separator}_={int(time.time())}"

            # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º —Ç–∞–π–º–∞—É—Ç –∏ –¥–æ–±–∞–≤–ª—è–µ–º connect timeout
            response = session.get(scan_url, timeout=(15, 75), allow_redirects=True)
            
            if response.status_code == 429:
                print("‚ö†Ô∏è Rate limit (429)! ")
                time.sleep(random.uniform(5, 10))
                change_ip()
                continue
            
            if response.status_code == 403:
                print("‚ö†Ô∏è –î–æ—Å—Ç—É–ø –∑–∞–ø—Ä–µ—â—ë–Ω (403)! ")
                time.sleep(random.uniform(5, 10))
                try:
                    session.close()
                except Exception:
                    pass
                session = get_session()
                warm_up_avito(session)
                continue

            # 302/—Ä–µ–¥–∏—Ä–µ–∫—Ç—ã —á–∞—Å—Ç–æ –æ–∑–Ω–∞—á–∞—é—Ç –∞–Ω—Ç–∏–±–æ—Ç/–∫–∞–ø—á—É. requests –æ–±—ã—á–Ω–æ —Å–ª–µ–¥—É–µ—Ç —Ä–µ–¥–∏—Ä–µ–∫—Ç–∞–º,
            # –Ω–æ –Ω–∞ –ê–≤–∏—Ç–æ –∏–Ω–æ–≥–¥–∞ –ø—Ä–∏–ª–µ—Ç–∞–µ—Ç 302 –±–µ–∑ –Ω–æ—Ä–º–∞–ª—å–Ω–æ–≥–æ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è.
            if response.status_code in (301, 302, 303, 307, 308):
                location = response.headers.get('Location', '')
                print(f"‚ö†Ô∏è –†–µ–¥–∏—Ä–µ–∫—Ç {response.status_code} -> {location[:60]}... ")
                time.sleep(random.uniform(8, 15))
                try:
                    session.close()
                except Exception:
                    pass
                session = get_session()
                warm_up_avito(session)
                continue
            
            if response.status_code != 200:
                print(f"‚ùå –û—à–∏–±–∫–∞ HTTP: {response.status_code}")
                if attempt < max_retries - 1:
                    time.sleep(random.uniform(5, 10))
                    try:
                        session.close()
                    except Exception:
                        pass
                    session = get_session()
                    warm_up_avito(session)
                    continue
                return []
            
            html = response.text

            # –î–µ—Ç–µ–∫—Ç –∞–Ω—Ç–∏–±–æ—Ç —Å—Ç—Ä–∞–Ω–∏—Ü—ã –ø–æ —Å–æ–¥–µ—Ä–∂–∏–º–æ–º—É
            if looks_like_block(html):
                print("‚ö†Ô∏è –ü–æ—Ö–æ–∂–µ –Ω–∞ –∞–Ω—Ç–∏–±–æ—Ç/–∫–∞–ø—á—É –ø–æ —Å–æ–¥–µ—Ä–∂–∏–º–æ–º—É. ")
                if attempt < max_retries - 1:
                    time.sleep(random.uniform(10, 20))
                    try:
                        session.close()
                    except Exception:
                        pass
                    session = get_session()
                    warm_up_avito(session)
                    continue
                return []

            break  # –£—Å–ø–µ—à–Ω—ã–π –∑–∞–ø—Ä–æ—Å, –≤—ã—Ö–æ–¥–∏–º –∏–∑ —Ü–∏–∫–ª–∞
            
        except requests.exceptions.Timeout as e:
            print(f"‚è±Ô∏è –¢–∞–π–º–∞—É—Ç (–ø–æ–ø—ã—Ç–∫–∞ {attempt + 1}): {e}")
            if attempt < max_retries - 1:
                print("üîÑ ")
                time.sleep(random.uniform(10, 20))
                try:
                    session.close()
                except Exception:
                    pass
                session = get_session()
                warm_up_avito(session)
                continue
            print("‚ùå –í—Å–µ –ø–æ–ø—ã—Ç–∫–∏ –∏—Å—á–µ—Ä–ø–∞–Ω—ã (—Ç–∞–π–º–∞—É—Ç)")
            return []
            
        except requests.exceptions.ConnectionError as e:
            print(f"üîå –û—à–∏–±–∫–∞ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è (–ø–æ–ø—ã—Ç–∫–∞ {attempt + 1}): {e}")
            if attempt < max_retries - 1:
                print("üîÑ ")
                time.sleep(random.uniform(10, 20))
                try:
                    session.close()
                except Exception:
                    pass
                session = get_session()
                warm_up_avito(session)
                continue
            print("‚ùå –í—Å–µ –ø–æ–ø—ã—Ç–∫–∏ –∏—Å—á–µ—Ä–ø–∞–Ω—ã (—Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ)")
            return []
            
        except Exception as e:
            print(f"‚ùå –ù–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è –æ—à–∏–±–∫–∞: {e}")
            return []
    else:
        # –¶–∏–∫–ª –∑–∞–≤–µ—Ä—à–∏–ª—Å—è –±–µ–∑ break ‚Äî –≤—Å–µ –ø–æ–ø—ã—Ç–∫–∏ –Ω–µ—É–¥–∞—á–Ω—ã
        print("‚ùå –í—Å–µ –ø–æ–ø—ã—Ç–∫–∏ –∏—Å—á–µ—Ä–ø–∞–Ω—ã")
        return []
    
    # –ü–∞—Ä—Å–∏–º HTML
    try:
        # –ò—â–µ–º JSON –¥–∞–Ω–Ω—ã–µ –≤ HTML
        # –ê–≤–∏—Ç–æ —Ö—Ä–∞–Ω–∏—Ç –¥–∞–Ω–Ω—ã–µ –≤ __initialData__
        json_match = re.search(r'window\.__initialData__\s*=\s*"(.+?)";', html)
        if json_match:
            # –î–µ–∫–æ–¥–∏—Ä—É–µ–º escaped JSON
            json_str = json_match.group(1)
            json_str = json_str.encode().decode('unicode_escape')
            data = json.loads(json_str)
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º items
            items = []
            if 'catalog' in str(data):
                # –†–µ–∫—É—Ä—Å–∏–≤–Ω–æ –∏—â–µ–º items
                def find_items(obj):
                    if isinstance(obj, dict):
                        if 'items' in obj and isinstance(obj['items'], list):
                            return obj['items']
                        for v in obj.values():
                            result = find_items(v)
                            if result:
                                return result
                    elif isinstance(obj, list):
                        for item in obj:
                            result = find_items(item)
                            if result:
                                return result
                    return None
                
                items = find_items(data) or []
            
            for item in items:
                if isinstance(item, dict) and 'id' in item:
                    try:
                        item_id = item.get('id')
                        title = item.get('title', '')
                        price_val = item.get('priceDetailed', {}).get('value') or item.get('price', 0)
                        
                        if isinstance(price_val, str):
                            price_val = int(re.sub(r'\D', '', price_val) or 0)
                        
                        url = f"https://www.avito.ru{item.get('urlPath', '')}" if item.get('urlPath') else f"https://www.avito.ru/moskva/noutbuki/{item_id}"
                        
                        if title and price_val and price_val > 10000:
                            listings.append({
                                'url': url,
                                'title': title,
                                'price': int(price_val)
                            })
                    except:
                        continue
        
        # Fallback: –ø–∞—Ä—Å–∏–º HTML –Ω–∞–ø—Ä—è–º—É—é
        if not listings:
            # –ò—â–µ–º –ø–∞—Ç—Ç–µ—Ä–Ω—ã –æ–±—ä—è–≤–ª–µ–Ω–∏–π
            item_pattern = r'data-marker="item"[^>]*>.*?href="(/[^"]+)".*?title="([^"]+)".*?data-marker="item-price"[^>]*>([^<]+)'
            matches = re.findall(item_pattern, html, re.DOTALL)
            
            for url_path, title, price_text in matches:
                try:
                    price = int(re.sub(r'\D', '', price_text) or 0)
                    if price > 10000:
                        listings.append({
                            'url': f'https://www.avito.ru{url_path}',
                            'title': title.strip(),
                            'price': price
                        })
                except:
                    continue
        
        print(f"üì¶ –ù–∞–π–¥–µ–Ω–æ {len(listings)} –æ–±—ä—è–≤–ª–µ–Ω–∏–π")
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ HTML: {e}")
    
    return listings


def find_hot_deals(listings: list[dict], prices_db: dict, seen_urls: set) -> list[HotDeal]:
    """–ù–∞—Ö–æ–¥–∏—Ç –≥–æ—Ä—è—á–∏–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è"""
    hot_deals = []
    
    for listing in listings:
        url = listing['url']
        
        # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —É–∂–µ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–µ
        if url in seen_urls:
            continue
        
        title = listing['title']
        price = listing['price']
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –º–æ–¥–µ–ª—å
        model = extract_model_from_title(title)
        if not model:
            continue
        
        # –ò—â–µ–º –º–µ–¥–∏–∞–Ω–Ω—É—é —Ü–µ–Ω—É
        median_price = None
        for db_model, db_median in prices_db.items():
            if model.lower() in db_model.lower() or db_model.lower() in model.lower():
                median_price = db_median
                break
        
        if not median_price:
            continue
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–∫–∏–¥–∫—É (—Ü–µ–Ω–∞ –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –Ω–∏–∂–µ –ø–æ—Ä–æ–≥–∞ –æ—Ç –º–µ–¥–∏–∞–Ω—ã)
        threshold_price = median_price * HOT_DEAL_THRESHOLD
        discount = 1 - (price / median_price)
        
        if price <= threshold_price:  # —Ü–µ–Ω–∞ <= 90% –æ—Ç –º–µ–¥–∏–∞–Ω—ã (—Å–∫–∏–¥–∫–∞ >= 10%)
            hot_deal = HotDeal(
                url=url,
                title=title,
                price=price,
                median_price=median_price,
                discount_percent=round(discount * 100, 1),
                model=model,
                found_at=datetime.now().isoformat()
            )
            hot_deals.append(hot_deal)
            print(f"üî• HOT DEAL: {title[:50]}... ‚Äî {price:,}‚ÇΩ (–º–µ–¥–∏–∞–Ω–∞: {median_price:,}‚ÇΩ, —Å–∫–∏–¥–∫–∞: {hot_deal.discount_percent}%)")
    
    return hot_deals


def send_telegram_notification(deals: list[HotDeal]):
    """–û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è –≤ Telegram"""
    notify_url = os.environ.get('TELEGRAM_NOTIFY_URL', '')
    
    if not notify_url:
        print("‚ö†Ô∏è TELEGRAM_NOTIFY_URL –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω")
        return
    
    for deal in deals:
        try:
            payload = {
                'deals': [asdict(deal)]
            }
            
            response = requests.post(
                notify_url,
                json=payload,
                headers={'Content-Type': 'application/json'},
                timeout=30
            )
            
            if response.status_code == 200:
                print(f"‚úÖ –û—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ –≤ Telegram: {deal.title[:40]}...")
            else:
                print(f"‚ùå –û—à–∏–±–∫–∞ Telegram: {response.status_code}")
                
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏: {e}")


def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è —Å–∫–∞–Ω–µ—Ä–∞"""
    print("=" * 60)
    print(f"üîç HOT DEALS SCANNER ‚Äî {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("=" * 60)
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ
    prices_db = load_prices_database()
    if not prices_db:
        print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –±–∞–∑—É —Ü–µ–Ω")
        return
    
    seen_urls = load_seen_deals()
    print(f"üìù –£–∂–µ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ: {len(seen_urls)} —Å–¥–µ–ª–æ–∫")
    
    # –°–æ–∑–¥–∞—ë–º —Å–µ—Å—Å–∏—é
    session = get_session()
    
    # –ü–∞—Ä—Å–∏–º –æ–±—ä—è–≤–ª–µ–Ω–∏—è
    listings = parse_listings(session)
    
    if not listings:
        print("‚ö†Ô∏è –û–±—ä—è–≤–ª–µ–Ω–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
        return
    
    # –ò—â–µ–º –≥–æ—Ä—è—á–∏–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è
    hot_deals = find_hot_deals(listings, prices_db, seen_urls)
    
    if hot_deals:
        print(f"\nüî• –ù–∞–π–¥–µ–Ω–æ {len(hot_deals)} –≥–æ—Ä—è—á–∏—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π!")
        
        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –≤ Telegram
        send_telegram_notification(hot_deals)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∫–∞–∫ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–µ
        for deal in hot_deals:
            seen_urls.add(deal.url)
        save_seen_deals(seen_urls)
    else:
        print("üòî –ì–æ—Ä—è—á–∏—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π –Ω–µ –Ω–∞–π–¥–µ–Ω–æ")
    
    print("\n‚úÖ –°–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ")


if __name__ == '__main__':
    main()
